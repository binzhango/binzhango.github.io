<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=http://binzhango.github.io/blog/2020/02/02/gradient-descent/ rel=canonical><link href=../../04/batch-normalization/ rel=next><link rel=icon href=../../../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.34"><title>Gradient Descent - Bin Zhang's Blog</title><link rel=stylesheet href=../../../../../assets/stylesheets/main.35f28582.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><meta property=og:type content=website><meta property=og:title content="Gradient Descent - Bin Zhang's Blog"><meta property=og:description content=None><meta property=og:image content=http://binzhango.github.io/assets/images/social/blog/posts/Gradient-Descent.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta content=http://binzhango.github.io/blog/2020/02/02/gradient-descent/ property=og:url><meta name=twitter:card content=summary_large_image><meta name=twitter:title content="Gradient Descent - Bin Zhang's Blog"><meta name=twitter:description content=None><meta name=twitter:image content=http://binzhango.github.io/assets/images/social/blog/posts/Gradient-Descent.png></head> <body dir=ltr> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#gradient-based-optimization-algorithms class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../../../.. title="Bin Zhang's Blog" class="md-header__button md-logo" aria-label="Bin Zhang's Blog" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Bin Zhang's Blog </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Gradient Descent </span> </div> </div> </div> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/binzhango title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> My GitHub Page </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../../.. class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../../../ class=md-tabs__link> Blog </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation hidden> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../../../.. title="Bin Zhang's Blog" class="md-nav__button md-logo" aria-label="Bin Zhang's Blog" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Bin Zhang's Blog </label> <div class=md-nav__source> <a href=https://github.com/binzhango title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> My GitHub Page </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../../../../.. class="md-nav__link "> <span class=md-ellipsis> Home </span> </a> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <div class="md-nav__link md-nav__container"> <a href=../../../../ class="md-nav__link "> <span class=md-ellipsis> Blog </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> Archive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../archive/2024/ class=md-nav__link> <span class=md-ellipsis> 2024 </span> </a> </li> <li class=md-nav__item> <a href=../../../../archive/2021/ class=md-nav__link> <span class=md-ellipsis> 2021 </span> </a> </li> <li class=md-nav__item> <a href=../../../../archive/2020/ class=md-nav__link> <span class=md-ellipsis> 2020 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../category/autogen/ class=md-nav__link> <span class=md-ellipsis> AutoGen </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/datafactory/ class=md-nav__link> <span class=md-ellipsis> DataFactory </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/k8s/ class=md-nav__link> <span class=md-ellipsis> K8s </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/llm/ class=md-nav__link> <span class=md-ellipsis> LLM </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/ml/ class=md-nav__link> <span class=md-ellipsis> ML </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/machine-learning/ class=md-nav__link> <span class=md-ellipsis> Machine Learning </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/python-learning/ class=md-nav__link> <span class=md-ellipsis> Python Learning </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/snowflake/ class=md-nav__link> <span class=md-ellipsis> Snowflake </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/spark/ class=md-nav__link> <span class=md-ellipsis> Spark </span> </a> </li> <li class=md-nav__item> <a href=../../../../category/airflow/ class=md-nav__link> <span class=md-ellipsis> airflow </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#gradient-descent-variants class=md-nav__link> <span class=md-ellipsis> Gradient Descent variants </span> </a> <nav class=md-nav aria-label="Gradient Descent variants"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#batch-gradient-descent-bgd class=md-nav__link> <span class=md-ellipsis> Batch Gradient Descent (BGD) </span> </a> </li> <li class=md-nav__item> <a href=#stochastic-gradient-descent-sgd class=md-nav__link> <span class=md-ellipsis> Stochastic Gradient Descent (SGD) </span> </a> </li> <li class=md-nav__item> <a href=#mini-batch-gradient-descent-mb-gd class=md-nav__link> <span class=md-ellipsis> Mini-batch Gradient Descent (MB-GD) </span> </a> </li> <li class=md-nav__item> <a href=#challenges class=md-nav__link> <span class=md-ellipsis> Challenges </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#gradient-descent-optimization-algorithms class=md-nav__link> <span class=md-ellipsis> Gradient Descent Optimization Algorithms </span> </a> <nav class=md-nav aria-label="Gradient Descent Optimization Algorithms"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#momentum class=md-nav__link> <span class=md-ellipsis> Momentum </span> </a> </li> <li class=md-nav__item> <a href=#nesterov-accelerated-gradient class=md-nav__link> <span class=md-ellipsis> Nesterov Accelerated Gradient </span> </a> </li> <li class=md-nav__item> <a href=#adagrad class=md-nav__link> <span class=md-ellipsis> Adagrad </span> </a> </li> <li class=md-nav__item> <a href=#adadelta class=md-nav__link> <span class=md-ellipsis> Adadelta </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-content md-content--post" data-md-component=content> <div class="md-sidebar md-sidebar--post" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class="md-sidebar__inner md-post"> <nav class="md-nav md-nav--primary"> <div class=md-post__back> <div class="md-nav__title md-nav__container"> <a href=../../../../ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> <span class=md-ellipsis> Back to index </span> </a> </div> </div> <ul class="md-post__meta md-nav__list"> <li class="md-nav__item md-nav__item--section"> <div class=md-post__title> <span class=md-ellipsis> Metadata </span> </div> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"/></svg> <time datetime="2020-02-02 21:04:06" class=md-ellipsis>February 2, 2020</time> </div> </li> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9 3v15h3V3zm3 2 4 13 3-1-4-13zM5 5v13h3V5zM3 19v2h18v-2z"/></svg> <span class=md-ellipsis> in <a href=../../../../category/machine-learning/ >Machine Learning</a></span> </div> </li> <li class=md-nav__item> <div class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7z"/></svg> <span class=md-ellipsis> 5 min read </span> </div> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <article class="md-content__inner md-typeset"> <nav class=md-tags> <span class=md-tag>ML</span> </nav> <h1 id=gradient-based-optimization-algorithms>gradient-based optimization algorithms<a class=headerlink href=#gradient-based-optimization-algorithms title="Permanent link">&para;</a></h1> <!-- more --> <h2 id=gradient-descent-variants>Gradient Descent variants<a class=headerlink href=#gradient-descent-variants title="Permanent link">&para;</a></h2> <h4 id=batch-gradient-descent-bgd>Batch Gradient Descent (BGD)<a class=headerlink href=#batch-gradient-descent-bgd title="Permanent link">&para;</a></h4> <p>Vanilla gradient descent, aka batch gradient descent, computes the gradient of the cost function w.r.t. to the parameters θ</p> <p>Batch gradient descent is guaranteed to converge - to the global minimum for convex error surfaces - to a local minimum for non-convex surfaces</p> <h4 id=stochastic-gradient-descent-sgd>Stochastic Gradient Descent (SGD)<a class=headerlink href=#stochastic-gradient-descent-sgd title="Permanent link">&para;</a></h4> <p>Batch gradient descent performs redundant computations for large datasets, as it recomputes gradients for similar examples before each parameter update. SGD does away with this redundancy by performing one update at a time. It is therefore usually much faster and can also be used to learn online. SGD performs frequent updates with a high variance that cause the objective function to <em>fluctuate</em> heavily. While batch gradient descent converges to the minimum of the basin the parameters are placed in, SGD's fluctuation, - enables it to jump to new and potentially better local minima - this ultimately complicates convergence to the exact minimum, as SGD will keep overshooting</p> <p>when we slowly decrease the learning rate, SGD shows the same convergence behavior as batch gradient descent, almost certainly converging to a <em>local</em> or the <em>global</em> minimum for <em>non-convex</em> and <em>convex</em> optimization respectively.</p> <h4 id=mini-batch-gradient-descent-mb-gd>Mini-batch Gradient Descent (MB-GD)<a class=headerlink href=#mini-batch-gradient-descent-mb-gd title="Permanent link">&para;</a></h4> <p>Mini-batch gradient descent finally takes the best of both worlds and performs an update for every mini-batch of n training examples</p> <ul> <li>reduces the variance of the parameter updates, which can lead to more stable convergence</li> <li>can make use of highly optimized matrix optimizations common to state-of-the-art deep learning libraries that make computing the gradient w.r.t. a mini-batch very efficient</li> <li>Mini-batch gradient descent is typically the algorithm of choice when training a neural network and the term SGD usually is employed also when mini-batches are used</li> </ul> <h4 id=challenges>Challenges<a class=headerlink href=#challenges title="Permanent link">&para;</a></h4> <ul> <li> <p><strong>Choosing a proper learning rate can be difficult.</strong></p> <blockquote> <p>A learning rate that is too small leads to painfully slow convergence, while a learning rate that is too large can hinder convergence and cause the loss function to fluctuate around the minimum or even to diverge.</p> </blockquote> </li> <li> <p><strong>Learning rete schedules try to adjust the learning rate during training</strong></p> <blockquote> <p>e.g. annealing, i.e. reducing the learning rate according to a pre-defined schedule or when the change in objective between epochs falls below a threshold. These schedules and thresholds, however, have to be defined in advance and are thus unable to adapt to a dataset's characteristics</p> </blockquote> </li> <li> <p><strong>The same learning rate applies to all parameter updates</strong></p> <blockquote> <p>If our data is sparse and our features have very different frequencies, we might not want to update all of them to the same extent, but perform a larger update for rarely occurring features</p> </blockquote> </li> <li> <p><strong>Minimizing high non-convex error functions common for neural networks is avoiding getting trapped in their numerous suboptimal local minima</strong></p> <blockquote> <p>The difficulty arises in fact not from local minima but from saddle points, i.e. points where one dimension slopes up and another slopes down. These saddle points are usually surrounded by a plateau of the same error, which makes it notoriously hard for SGD to escape, as the gradient is close to zero in all dimensions.</p> </blockquote> </li> </ul> <h2 id=gradient-descent-optimization-algorithms>Gradient Descent Optimization Algorithms<a class=headerlink href=#gradient-descent-optimization-algorithms title="Permanent link">&para;</a></h2> <p>We will not discuss algorithms that are infeasible to compute in practice for high-dimensional data sets, e.g. second-order methods such as Newton's method.</p> <h4 id=momentum>Momentum<a class=headerlink href=#momentum title="Permanent link">&para;</a></h4> <p>SGD has trouble navigating ravines, i.e. areas where the surface curves much more steeply in one dimension than in another, which are common around local optima.</p> <p>Some implementations exchange the signs in the equations. The momentum term γ is usually set to 0.9 or a similar value.</p> <p>When using momentum, we push a ball down a hill. The ball accumulates momentum as it rolls downhill, becoming faster and faster on the way (until it reaches its terminal velocity if there is air resistance, i.e. γ&lt;1). <em>The same thing happens to our parameter updates</em>: </p> <blockquote> <p>The momentum term increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. As a result, we gain <em>faster convergence and reduced oscillation</em>.</p> </blockquote> <h4 id=nesterov-accelerated-gradient>Nesterov Accelerated Gradient<a class=headerlink href=#nesterov-accelerated-gradient title="Permanent link">&para;</a></h4> <p>We'd like to have a smarter ball, a ball that has a notion of where it is going so that it knows to slow down before the hill slopes up again. Nesterov Accelerated Gradient (NAG) is a way to give our momentum term this kind of prescience. We know that we will use our momentum term γvθ<sub>t-1</sub> to move the parameters θ. Computing θ−γv<sub>t-1</sub> thus gives us an approximation of the next position of the parameters (the gradient is missing for the full update), a rough idea where our parameters are going to be. We can now effectively look ahead by calculating the gradient <em>not w.r.t. to our current parameters θ but w.r.t. the approximate future position of our parameters</em></p> <p>we are able to adapt our updates to the slope of our error function and speed up SGD in turn, we would also like to adapt our updates to each individual parameter to perform larger or smaller updates depending on their importance</p> <p>The distinction between Momentum method and Nesterov Accelerated Gradient updates was - Both methods are distinct only when the learning rate η is reasonably large. - When the learning rate η is relatively large, Nesterov Accelerated Gradients allows larger decay rate α than Momentum method, while preventing oscillations. - Both Momentum method and Nesterov Accelerated Gradient <strong>become equivalent when η is small</strong></p> <h4 id=adagrad>Adagrad<a class=headerlink href=#adagrad title="Permanent link">&para;</a></h4> <p>Adagrad is an algorithm for gradient-based optimization that does just this: It adapts the learning rate to the parameters, - performing smaller updates (i.e. low learning rates) for parameters associated with frequently occurring features, - and larger updates (i.e. high learning rates) for parameters associated with infrequent features.</p> <p>For this reason, <strong>it is well-suited for dealing with sparse data.</strong></p> <p>Previously, we performed an update for all parameters θ at once as every parameter θ<sub>i</sub> used the same learning rate η. As Adagrad uses a different learning rate for every parameter θ<sub>i</sub> at every time step t, we first show Adagrad's per-parameter update, which we then vectorize. For brevity, we use gt to denote the gradient at time step t. g<sub>t,i</sub> is then the partial derivative of the objective function w.r.t. to the parameter θ<sub>i</sub> at time step t</p> <p>In its update rule, Adagrad modifies the general learning rate η at each time step t for every parameter θ<sub>i</sub> based on the past gradients that have been computed for θ<sub>i</sub></p> <p>θ<sub>t+1,i</sub>=θ<sub>t,i</sub>−η/√(G<sub>t,ii</sub>+ϵ)⋅g<sub>t,i</sub></p> <p>G<sub>t</sub>∈R<sup>d×d</sup> here is a diagonal matrix where each diagonal element i,i is the sum of the squares of the gradients w.r.t. θ<sub>i</sub> up to time step t, while ϵ is a smoothing term that avoids division by zero. <strong>Interestingly, without the square root operation, the algorithm performs much worse.</strong></p> <ul> <li>One of Adagrad's main benefits is that it eliminates the need to manually tune the learning rate</li> <li>Adagrad's main weakness is its accumulation of the squared gradients in the denominator<blockquote> <p>Since every added term is positive, the accumulated sum keeps growing during training. This in turn causes the learning rate to shrink and eventually become infinitesimally small, at which point the algorithm is no longer able to acquire additional knowledge. The following algorithms aim to resolve this flaw.</p> </blockquote> </li> </ul> <h4 id=adadelta>Adadelta<a class=headerlink href=#adadelta title="Permanent link">&para;</a></h4> <p>Adadelta is an extension of Adagrad that seeks to its aggressive, monotonically decreasing learning rate. Instead of accumulating all past squared gradients, Adadelta restricts the window of accumulated past gradients to some fixed size w.</p> <p>Instead of inefficiently storing w previous squared gradients, the sum of gradients is recursively defined as a decaying average of all past squared gradients. </p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../04/batch-normalization/ class="md-footer__link md-footer__link--next" aria-label="Next: Batch Normalization"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Batch Normalization </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/binzhango target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../../../..", "features": ["navigation.footer", "navigation.indexes", "navigation.top", "navigation.sections", "navigation.tabs", "content.code.copy"], "search": "../../../../../assets/javascripts/workers/search.07f07601.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../../../assets/javascripts/bundle.56dfad97.min.js></script> </body> </html>