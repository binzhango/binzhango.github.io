<!DOCTYPE html><html lang="en" dir="ltr" data-theme="dark" data-has-toc data-has-sidebar class="astro-bguv2lll"> <head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><title>LLM Interview Questions | B~~~~~Z</title><link rel="canonical" href="https://binzhango.com/posts/2025/10-30-llm-interview/"/><link rel="sitemap" href="/sitemap-index.xml"/><link rel="shortcut icon" href="/favicon.svg" type="image/svg+xml"/><meta name="generator" content="Astro v5.17.1"/><meta name="generator" content="Starlight v0.37.6"/><meta property="og:title" content="LLM Interview Questions"/><meta property="og:type" content="article"/><meta property="og:url" content="https://binzhango.com/posts/2025/10-30-llm-interview/"/><meta property="og:locale" content="en"/><meta property="og:site_name" content="B~~~~~Z"/><meta name="twitter:card" content="summary_large_image"/> <!-- Theme Manager - handles theme initialization and persistence --> <script data-default-theme="light">
  window.theme ??= (() => {
    const defaultTheme = document.currentScript.getAttribute("data-default-theme");
    const storageKey = "starlight-theme";
    const store =
      typeof localStorage !== "undefined"
        ? localStorage
        : { getItem: () => null, setItem: () => {} };
    
    const mediaMatcher = window.matchMedia("(prefers-color-scheme: light)");
    let systemTheme = mediaMatcher.matches ? "light" : "dark";
    
    mediaMatcher.addEventListener("change", (event) => {
      systemTheme = event.matches ? "light" : "dark";
      applyTheme(getTheme());
    });
    
    function applyTheme(theme) {
      const resolvedTheme = theme === "auto" ? systemTheme : theme;
      document.documentElement.dataset.theme = resolvedTheme;
      document.documentElement.setAttribute("data-theme", resolvedTheme);
      document.documentElement.style.colorScheme = resolvedTheme;
      
      document.dispatchEvent(
        new CustomEvent("theme-changed", {
          detail: { theme, systemTheme, defaultTheme },
        })
      );
    }
    
    function setTheme(theme = defaultTheme) {
      store.setItem(storageKey, theme);
      applyTheme(theme);
    }
    
    function getTheme() {
      return store.getItem(storageKey) || defaultTheme;
    }
    
    function getSystemTheme() {
      return systemTheme;
    }
    
    function getDefaultTheme() {
      return defaultTheme;
    }
    
    return { setTheme, getTheme, getSystemTheme, getDefaultTheme };
  })();
  
  // Set initial theme
  theme.setTheme(theme.getTheme());
</script> <script type="module">document.addEventListener("astro:after-swap",()=>{window.theme&&window.theme.setTheme(window.theme.getTheme())});</script> <!-- Meta description --> <meta name="description" content="A blog about Python, Kubernetes, Spark, Machine Learning, and more"> <!-- Canonical URL --> <link rel="canonical" href="https://binzhango.com/posts/2025/10-30-llm-interview/"> <!-- Open Graph meta tags --> <meta property="og:type" content="article"> <meta property="og:title" content="LLM Interview Questions"> <meta property="og:description" content="A blog about Python, Kubernetes, Spark, Machine Learning, and more"> <meta property="og:url" content="https://binzhango.com/posts/2025/10-30-llm-interview/"> <meta property="og:image" content="https://binzhango.com/og/posts/2025/10-30-llm-interview.png"> <meta property="og:image:width" content="1200"> <meta property="og:image:height" content="630"> <meta property="og:image:alt" content="LLM Interview Questions"> <meta property="og:site_name" content="B~~~~~Z"> <meta property="og:locale" content="en_US">  <meta property="article:published_time" content="2025-10-30T00:00:00.000Z"> <meta property="article:author" content="BZ"> <meta property="article:section" content="LLM"> <!-- Twitter Card meta tags --> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:title" content="LLM Interview Questions"> <meta name="twitter:description" content="A blog about Python, Kubernetes, Spark, Machine Learning, and more"> <meta name="twitter:image" content="https://binzhango.com/og/posts/2025/10-30-llm-interview.png"> <meta name="twitter:image:alt" content="LLM Interview Questions"> <meta name="twitter:site" content="@binzhangtw"> <meta name="twitter:creator" content="@binzhangtw"> <script type="module">function s(){document.querySelectorAll("pre[data-language], .astro-code").forEach(n=>{if(n.parentElement?.classList.contains("code-block-wrapper"))return;const r=document.createElement("div");r.className="code-block-wrapper";const e=document.createElement("button");e.className="copy-button",e.setAttribute("aria-label","Copy code to clipboard"),e.innerHTML=`
        <svg class="copy-icon" aria-hidden="true" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
          <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
        </svg>
        <span class="copy-text">Copy</span>
      `,e.addEventListener("click",async()=>{const c=n.querySelector("code");if(!c)return;const i=c.querySelectorAll(".line, .ec-line");let a;i.length>0?a=Array.from(i).map(t=>{const o=t.querySelector(".code");return o?o.textContent||"":t.textContent||""}).join(`
`):a=c.textContent||"";try{await navigator.clipboard.writeText(a);const t=e.querySelector(".copy-text");t&&(t.textContent="Copied!"),e.classList.add("copied"),setTimeout(()=>{t&&(t.textContent="Copy"),e.classList.remove("copied")},2e3)}catch(t){console.error("Failed to copy code:",t);const o=e.querySelector(".copy-text");o&&(o.textContent="Failed"),setTimeout(()=>{o&&(o.textContent="Copy")},2e3)}}),n.parentNode?.insertBefore(r,n),r.appendChild(n),r.appendChild(e)})}s();document.addEventListener("astro:page-load",s);</script> <!-- Load GLightbox CSS --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.1/dist/css/glightbox.min.css"><!-- Load GLightbox JavaScript and initialize --><script type="module" src="/_astro/Lightbox.astro_astro_type_script_index_0_lang.CzG1Bwil.js"></script> <!-- Load Starlight Tabs script --> <script type="module" src="/node_modules/@astrojs/starlight/user-components/Tabs.astro?astro&type=script&index=0&lang.ts"></script> <!-- Force theme colors to load after Starlight's CSS --> <style>
    /* Force light theme background colors */
    :root[data-theme='light'],
    :root[data-theme='light'] body,
    :root[data-theme='light'] html {
        --sl-color-bg: #f9fafb !important;
        --sl-color-white: #f9fafb !important;
        background-color: #f9fafb !important;
    }
    
    :root[data-theme='light'] .page,
    :root[data-theme='light'] main.main {
        background-color: #f9fafb !important;
    }
    
    /* White content areas in light mode */
    :root[data-theme='light'] .content-panel,
    :root[data-theme='light'] article,
    :root[data-theme='light'] .sl-container {
        background-color: #ffffff !important;
    }
    
    /* Force dark theme background colors */
    :root[data-theme='dark'],
    :root[data-theme='dark'] body,
    :root[data-theme='dark'] html {
        --sl-color-bg: #0a0a0a !important;
        --sl-color-white: #0a0a0a !important;
        background-color: #0a0a0a !important;
    }
    
    :root[data-theme='dark'] .page,
    :root[data-theme='dark'] main.main {
        background-color: #0a0a0a !important;
    }
</style> <script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"LLM Interview Questions","description":"A blog about Python, Kubernetes, Spark, Machine Learning, and more","author":{"@type":"Person","name":"BZ"},"datePublished":"2025-10-30T00:00:00.000Z","dateModified":"2025-10-30T00:00:00.000Z","image":"https://binzhango.com/og/posts/2025/10-30-llm-interview.png","url":"https://binzhango.com/posts/2025/10-30-llm-interview/","publisher":{"@type":"Organization","name":"B~~~~~Z","logo":{"@type":"ImageObject","url":"https://binzhango.com/assets/favicon.ico"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://binzhango.com/posts/2025/10-30-llm-interview/"},"keywords":"","articleSection":"LLM"}</script><script>
	window.StarlightThemeProvider = (() => {
		const storedTheme =
			typeof localStorage !== 'undefined' && localStorage.getItem('starlight-theme');
		const theme =
			storedTheme ||
			(window.matchMedia('(prefers-color-scheme: light)').matches ? 'light' : 'dark');
		document.documentElement.dataset.theme = theme === 'light' ? 'light' : 'dark';
		return {
			updatePickers(theme = storedTheme || 'auto') {
				document.querySelectorAll('starlight-theme-select').forEach((picker) => {
					const select = picker.querySelector('select');
					if (select) select.value = theme;
					/** @type {HTMLTemplateElement | null} */
					const tmpl = document.querySelector(`#theme-icons`);
					const newIcon = tmpl && tmpl.content.querySelector('.' + theme);
					if (newIcon) {
						const oldIcon = picker.querySelector('svg.label-icon');
						if (oldIcon) {
							oldIcon.replaceChildren(...newIcon.cloneNode(true).childNodes);
						}
					}
				});
			},
		};
	})();
</script><template id="theme-icons"><svg aria-hidden="true" class="light astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M5 12a1 1 0 0 0-1-1H3a1 1 0 0 0 0 2h1a1 1 0 0 0 1-1Zm.64 5-.71.71a1 1 0 0 0 0 1.41 1 1 0 0 0 1.41 0l.71-.71A1 1 0 0 0 5.64 17ZM12 5a1 1 0 0 0 1-1V3a1 1 0 0 0-2 0v1a1 1 0 0 0 1 1Zm5.66 2.34a1 1 0 0 0 .7-.29l.71-.71a1 1 0 1 0-1.41-1.41l-.66.71a1 1 0 0 0 0 1.41 1 1 0 0 0 .66.29Zm-12-.29a1 1 0 0 0 1.41 0 1 1 0 0 0 0-1.41l-.71-.71a1.004 1.004 0 1 0-1.43 1.41l.73.71ZM21 11h-1a1 1 0 0 0 0 2h1a1 1 0 0 0 0-2Zm-2.64 6A1 1 0 0 0 17 18.36l.71.71a1 1 0 0 0 1.41 0 1 1 0 0 0 0-1.41l-.76-.66ZM12 6.5a5.5 5.5 0 1 0 5.5 5.5A5.51 5.51 0 0 0 12 6.5Zm0 9a3.5 3.5 0 1 1 0-7 3.5 3.5 0 0 1 0 7Zm0 3.5a1 1 0 0 0-1 1v1a1 1 0 0 0 2 0v-1a1 1 0 0 0-1-1Z"/></svg><svg aria-hidden="true" class="dark astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M21.64 13a1 1 0 0 0-1.05-.14 8.049 8.049 0 0 1-3.37.73 8.15 8.15 0 0 1-8.14-8.1 8.59 8.59 0 0 1 .25-2A1 1 0 0 0 8 2.36a10.14 10.14 0 1 0 14 11.69 1 1 0 0 0-.36-1.05Zm-9.5 6.69A8.14 8.14 0 0 1 7.08 5.22v.27a10.15 10.15 0 0 0 10.14 10.14 9.784 9.784 0 0 0 2.1-.22 8.11 8.11 0 0 1-7.18 4.32v-.04Z"/></svg><svg aria-hidden="true" class="auto astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M21 14h-1V7a3 3 0 0 0-3-3H7a3 3 0 0 0-3 3v7H3a1 1 0 0 0-1 1v2a3 3 0 0 0 3 3h14a3 3 0 0 0 3-3v-2a1 1 0 0 0-1-1ZM6 7a1 1 0 0 1 1-1h10a1 1 0 0 1 1 1v7H6V7Zm14 10a1 1 0 0 1-1 1H5a1 1 0 0 1-1-1v-1h16v1Z"/></svg></template><link rel="stylesheet" href="/_astro/print.DNXP8c50.css" media="print"><link rel="stylesheet" href="/_astro/_year_.D1sIbZgm.css">
<style>@layer starlight.components{:root{--sl-badge-default-border: var(--sl-color-accent);--sl-badge-default-bg: var(--sl-color-accent-low);--sl-badge-default-text: #fff;--sl-badge-note-border: var(--sl-color-blue);--sl-badge-note-bg: var(--sl-color-blue-low);--sl-badge-note-text: #fff;--sl-badge-danger-border: var(--sl-color-red);--sl-badge-danger-bg: var(--sl-color-red-low);--sl-badge-danger-text: #fff;--sl-badge-success-border: var(--sl-color-green);--sl-badge-success-bg: var(--sl-color-green-low);--sl-badge-success-text: #fff;--sl-badge-caution-border: var(--sl-color-orange);--sl-badge-caution-bg: var(--sl-color-orange-low);--sl-badge-caution-text: #fff;--sl-badge-tip-border: var(--sl-color-purple);--sl-badge-tip-bg: var(--sl-color-purple-low);--sl-badge-tip-text: #fff}[data-theme=light]:root{--sl-badge-default-bg: var(--sl-color-accent-high);--sl-badge-note-bg: var(--sl-color-blue-high);--sl-badge-danger-bg: var(--sl-color-red-high);--sl-badge-success-bg: var(--sl-color-green-high);--sl-badge-caution-bg: var(--sl-color-orange-high);--sl-badge-tip-bg: var(--sl-color-purple-high)}.sl-badge:where(.astro-avdet4wd){display:inline-block;border:1px solid var(--sl-color-border-badge);border-radius:.25rem;font-family:var(--sl-font-system-mono);line-height:normal;color:var(--sl-color-text-badge);background-color:var(--sl-color-bg-badge);overflow-wrap:anywhere}.sidebar-content .sl-badge:where(.astro-avdet4wd){line-height:1;font-size:var(--sl-text-xs);padding:.125rem .375rem}.sidebar-content a[aria-current=page]>.sl-badge:where(.astro-avdet4wd){--sl-color-bg-badge: transparent;--sl-color-border-badge: currentColor;color:inherit}.default:where(.astro-avdet4wd){--sl-color-bg-badge: var(--sl-badge-default-bg);--sl-color-border-badge: var(--sl-badge-default-border);--sl-color-text-badge: var(--sl-badge-default-text)}.note:where(.astro-avdet4wd){--sl-color-bg-badge: var(--sl-badge-note-bg);--sl-color-border-badge: var(--sl-badge-note-border);--sl-color-text-badge: var(--sl-badge-note-text)}.danger:where(.astro-avdet4wd){--sl-color-bg-badge: var(--sl-badge-danger-bg);--sl-color-border-badge: var(--sl-badge-danger-border);--sl-color-text-badge: var(--sl-badge-danger-text)}.success:where(.astro-avdet4wd){--sl-color-bg-badge: var(--sl-badge-success-bg);--sl-color-border-badge: var(--sl-badge-success-border);--sl-color-text-badge: var(--sl-badge-success-text)}.tip:where(.astro-avdet4wd){--sl-color-bg-badge: var(--sl-badge-tip-bg);--sl-color-border-badge: var(--sl-badge-tip-border);--sl-color-text-badge: var(--sl-badge-tip-text)}.caution:where(.astro-avdet4wd){--sl-color-bg-badge: var(--sl-badge-caution-bg);--sl-color-border-badge: var(--sl-badge-caution-border);--sl-color-text-badge: var(--sl-badge-caution-text)}.small:where(.astro-avdet4wd){font-size:var(--sl-text-xs);padding:.125rem .25rem}.medium:where(.astro-avdet4wd){font-size:var(--sl-text-sm);padding:.175rem .35rem}.large:where(.astro-avdet4wd){font-size:var(--sl-text-base);padding:.225rem .45rem}.sl-markdown-content :is(h1,h2,h3,h4,h5,h6) .sl-badge:where(.astro-avdet4wd){vertical-align:middle}}
@layer starlight.components{.card:where(.astro-v5tidmuc){--sl-card-border: var(--sl-color-purple);--sl-card-bg: var(--sl-color-purple-low);border:1px solid var(--sl-color-gray-5);background-color:var(--sl-color-black);padding:clamp(1rem,calc(.125rem + 3vw),2.5rem);flex-direction:column;gap:clamp(.5rem,calc(.125rem + 1vw),1rem)}.card:where(.astro-v5tidmuc):nth-child(4n+1){--sl-card-border: var(--sl-color-orange);--sl-card-bg: var(--sl-color-orange-low)}.card:where(.astro-v5tidmuc):nth-child(4n+3){--sl-card-border: var(--sl-color-green);--sl-card-bg: var(--sl-color-green-low)}.card:where(.astro-v5tidmuc):nth-child(4n+4){--sl-card-border: var(--sl-color-red);--sl-card-bg: var(--sl-color-red-low)}.card:where(.astro-v5tidmuc):nth-child(4n+5){--sl-card-border: var(--sl-color-blue);--sl-card-bg: var(--sl-color-blue-low)}.title:where(.astro-v5tidmuc){font-weight:600;font-size:var(--sl-text-h4);color:var(--sl-color-white);line-height:var(--sl-line-height-headings);gap:1rem;align-items:center}.card:where(.astro-v5tidmuc) .icon:where(.astro-v5tidmuc){border:1px solid var(--sl-card-border);background-color:var(--sl-card-bg);padding:.2em;border-radius:.25rem;flex-shrink:0}.card:where(.astro-v5tidmuc) .body:where(.astro-v5tidmuc){margin:0;font-size:clamp(var(--sl-text-sm),calc(.5rem + 1vw),var(--sl-text-body))}}
@layer starlight.components{.card-grid:where(.astro-zntqmydn){display:grid;grid-template-columns:100%;gap:1rem}.card-grid:where(.astro-zntqmydn)>*{margin-top:0!important}@media(min-width:50rem){.card-grid:where(.astro-zntqmydn){grid-template-columns:1fr 1fr;gap:1.5rem}.stagger:where(.astro-zntqmydn){--stagger-height: 5rem;padding-bottom:var(--stagger-height)}.stagger:where(.astro-zntqmydn)>*:nth-child(2n){transform:translateY(var(--stagger-height))}}}
@layer starlight.components{svg:where(.astro-c6vsoqas){color:var(--sl-icon-color);font-size:var(--sl-icon-size, 1em);width:1em;height:1em}}
@layer starlight.components{.sl-link-card:where(.astro-mf7fz2mj){display:grid;grid-template-columns:1fr auto;gap:.5rem;border:1px solid var(--sl-color-gray-5);border-radius:.5rem;padding:1rem;box-shadow:var(--sl-shadow-sm);position:relative}a:where(.astro-mf7fz2mj){text-decoration:none;line-height:var(--sl-line-height-headings)}a:where(.astro-mf7fz2mj):before{content:"";position:absolute;inset:0}.stack:where(.astro-mf7fz2mj){flex-direction:column;gap:.5rem}.title:where(.astro-mf7fz2mj){color:var(--sl-color-white);font-weight:600;font-size:var(--sl-text-lg)}.description:where(.astro-mf7fz2mj){color:var(--sl-color-gray-3);line-height:1.5}.icon:where(.astro-mf7fz2mj){color:var(--sl-color-gray-3)}.sl-link-card:where(.astro-mf7fz2mj):hover{background:var(--sl-color-gray-7, var(--sl-color-gray-6));border-color:var(--sl-color-gray-2)}.sl-link-card:where(.astro-mf7fz2mj):hover .icon:where(.astro-mf7fz2mj){color:var(--sl-color-white)}}
@layer starlight.components{.sl-steps{--bullet-size: calc(var(--sl-line-height) * 1rem);--bullet-margin: .375rem;list-style:none;counter-reset:steps-counter var(--sl-steps-start, 0);padding-inline-start:0}.sl-steps>li{counter-increment:steps-counter;position:relative;padding-inline-start:calc(var(--bullet-size) + 1rem);padding-bottom:1px;min-height:calc(var(--bullet-size) + var(--bullet-margin))}.sl-steps>li+li{margin-top:0}.sl-steps>li:before{content:counter(steps-counter);position:absolute;top:0;inset-inline-start:0;width:var(--bullet-size);height:var(--bullet-size);line-height:var(--bullet-size);font-size:var(--sl-text-xs);font-weight:600;text-align:center;color:var(--sl-color-white);background-color:var(--sl-color-gray-6);border-radius:99rem;box-shadow:inset 0 0 0 1px var(--sl-color-gray-5)}.sl-steps>li:after{--guide-width: 1px;content:"";position:absolute;top:calc(var(--bullet-size) + var(--bullet-margin));bottom:var(--bullet-margin);inset-inline-start:calc((var(--bullet-size) - var(--guide-width)) / 2);width:var(--guide-width);background-color:var(--sl-color-hairline-light)}}@layer starlight.content{.sl-steps>li>:first-child{--lh: calc(1em * var(--sl-line-height));--shift-y: calc(.5 * (var(--bullet-size) - var(--lh)));transform:translateY(var(--shift-y));margin-bottom:var(--shift-y)}.sl-steps>li>:first-child:where(h1,h2,h3,h4,h5,h6){--lh: calc(1em * var(--sl-line-height-headings))}@supports (--prop: 1lh){.sl-steps>li>:first-child{--lh: 1lh}}}
@layer starlight.components{.sl-link-button:where(.astro-xwgiixxa){align-items:center;border:1px solid transparent;border-radius:999rem;display:inline-flex;font-size:var(--sl-text-sm);gap:.5em;line-height:1.1875;outline-offset:.25rem;padding:.4375rem 1.125rem;text-decoration:none}.sl-link-button:where(.astro-xwgiixxa).primary{background:var(--sl-color-text-accent);border-color:var(--sl-color-text-accent);color:var(--sl-color-black)}.sl-link-button:where(.astro-xwgiixxa).primary:hover{color:var(--sl-color-black)}.sl-link-button:where(.astro-xwgiixxa).secondary{border-color:inherit;color:var(--sl-color-white)}.sl-link-button:where(.astro-xwgiixxa).minimal{color:var(--sl-color-white);padding-inline:0}.sl-link-button:where(.astro-xwgiixxa) svg{flex-shrink:0}@media(min-width:50rem){.sl-link-button:where(.astro-xwgiixxa){font-size:var(--sl-text-base);padding:.9375rem 1.25rem}}.sl-markdown-content .sl-link-button:where(.astro-xwgiixxa){margin-inline-end:1rem}.sl-markdown-content .sl-link-button:where(.astro-xwgiixxa):not(:where(p *)){margin-block:1rem}}
</style><script type="module" src="/_astro/page.B1D-nYk3.js"></script></head> <body class="astro-bguv2lll"> <a href="#_top" class="astro-7q3lir66">Skip to content</a>  <div class="page sl-flex astro-vrdttmbt"> <header class="header astro-vrdttmbt"><button id="sidebar-toggle" class="sidebar-toggle-btn astro-lp5naqcd" aria-label="Toggle sidebar"> <svg width="20" height="20" viewBox="0 0 20 20" fill="none" stroke="currentColor" class="astro-lp5naqcd"> <path d="M3 6h14M3 10h14M3 14h14" stroke-width="2" stroke-linecap="round" class="astro-lp5naqcd"></path> </svg> </button> <script type="module">function o(){const e=document.getElementById("sidebar-toggle"),i=document.querySelector("[data-starlight-sidebar]")||document.querySelector(".sidebar");if(!e||!i)return;localStorage.getItem("sidebar-hidden")==="true"&&(document.body.classList.add("sidebar-hidden"),e.innerHTML='<svg width="20" height="20" viewBox="0 0 20 20" fill="none" stroke="currentColor"><path d="M8 5l5 5-5 5" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>'),e.addEventListener("click",()=>{const t=document.body.classList.toggle("sidebar-hidden");t?e.innerHTML='<svg width="20" height="20" viewBox="0 0 20 20" fill="none" stroke="currentColor"><path d="M8 5l5 5-5 5" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>':e.innerHTML='<svg width="20" height="20" viewBox="0 0 20 20" fill="none" stroke="currentColor"><path d="M3 6h14M3 10h14M3 14h14" stroke-width="2" stroke-linecap="round"/></svg>',localStorage.setItem("sidebar-hidden",t.toString())})}o();document.addEventListener("astro:page-load",o);</script> <div class="header-wrapper astro-3ef6ksr2"> <div class="header sl-flex astro-3ef6ksr2"> <!-- Logo and Name on the left --> <a href="/" class="site-logo sl-flex astro-3ef6ksr2"> <img src="/assets/favicon.ico" alt="B~~~~~Z" class="logo-icon astro-3ef6ksr2"> <span class="site-name astro-3ef6ksr2">B~~~~~Z</span> </a> <!-- Navigation and controls on the right --> <div class="header-right sl-flex astro-3ef6ksr2"> <!-- Navigation Links --> <nav class="header-nav sl-flex astro-3ef6ksr2"> <a href="/" class="nav-link astro-3ef6ksr2">home</a> <a href="/posts/2025/03-29-llm-usage" class="nav-link astro-3ef6ksr2">blog</a> <a href="/archive/" class="nav-link astro-3ef6ksr2">archive</a> <a href="https://github.com/binzhango" target="_blank" rel="noopener noreferrer" class="nav-link astro-3ef6ksr2">about</a> </nav> <!-- Search and Controls --> <div class="header-controls sl-flex astro-3ef6ksr2"> <div class="search-wrapper astro-3ef6ksr2"> <site-search class="astro-3ef6ksr2 astro-v37mnknz" data-translations="{&#34;placeholder&#34;:&#34;Search&#34;}"> <button data-open-modal disabled aria-label="Search" aria-keyshortcuts="Control+K" class="astro-v37mnknz"> <svg aria-hidden="true" class="astro-v37mnknz astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M21.71 20.29 18 16.61A9 9 0 1 0 16.61 18l3.68 3.68a.999.999 0 0 0 1.42 0 1 1 0 0 0 0-1.39ZM11 18a7 7 0 1 1 0-14 7 7 0 0 1 0 14Z"/></svg> <span class="sl-hidden md:sl-block astro-v37mnknz" aria-hidden="true">Search</span> <kbd class="sl-hidden md:sl-flex astro-v37mnknz" style="display: none;"> <kbd class="astro-v37mnknz">Ctrl</kbd><kbd class="astro-v37mnknz">K</kbd> </kbd> </button> <dialog style="padding:0" aria-label="Search" class="astro-v37mnknz"> <div class="dialog-frame sl-flex astro-v37mnknz">  <button data-close-modal class="sl-flex md:sl-hidden astro-v37mnknz"> Cancel </button> <div class="search-container astro-v37mnknz"> <div id="starlight__search" class="astro-v37mnknz"></div> </div> </div> </dialog> </site-search>  <script>
	(() => {
		const openBtn = document.querySelector('button[data-open-modal]');
		const shortcut = openBtn?.querySelector('kbd');
		if (!openBtn || !(shortcut instanceof HTMLElement)) return;
		const platformKey = shortcut.querySelector('kbd');
		if (platformKey && /(Mac|iPhone|iPod|iPad)/i.test(navigator.platform)) {
			platformKey.textContent = 'âŒ˜';
			openBtn.setAttribute('aria-keyshortcuts', 'Meta+K');
		}
		shortcut.style.display = '';
	})();
</script> <script type="module" src="/_astro/Search.astro_astro_type_script_index_0_lang.cjYDvRdi.js"></script>   </div>  <button id="theme-toggle" type="button" aria-label="Toggle theme" class="theme-toggle astro-x3pjskd3"> <svg class="sun-icon astro-x3pjskd3" aria-hidden="true" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"> <circle cx="12" cy="12" r="5" class="astro-x3pjskd3"></circle> <line x1="12" y1="1" x2="12" y2="3" class="astro-x3pjskd3"></line> <line x1="12" y1="21" x2="12" y2="23" class="astro-x3pjskd3"></line> <line x1="4.22" y1="4.22" x2="5.64" y2="5.64" class="astro-x3pjskd3"></line> <line x1="18.36" y1="18.36" x2="19.78" y2="19.78" class="astro-x3pjskd3"></line> <line x1="1" y1="12" x2="3" y2="12" class="astro-x3pjskd3"></line> <line x1="21" y1="12" x2="23" y2="12" class="astro-x3pjskd3"></line> <line x1="4.22" y1="19.78" x2="5.64" y2="18.36" class="astro-x3pjskd3"></line> <line x1="18.36" y1="5.64" x2="19.78" y2="4.22" class="astro-x3pjskd3"></line> </svg> <svg class="moon-icon astro-x3pjskd3" aria-hidden="true" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"> <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z" class="astro-x3pjskd3"></path> </svg> </button>  <script type="module">function n(){const e=document.getElementById("theme-toggle");e&&e.addEventListener("click",()=>{if(window.theme){const t=window.theme.getTheme(),o=(t==="auto"?window.theme.getSystemTheme():t)==="dark"?"light":"dark";window.theme.setTheme(o)}})}n();document.addEventListener("astro:after-swap",()=>{n()});</script>  <a href="https://github.com/binzhango" rel="me" class="sl-flex astro-wy4te6ga"><span class="sr-only astro-wy4te6ga">GitHub</span><svg aria-hidden="true" class="astro-wy4te6ga astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M12 .3a12 12 0 0 0-3.8 23.38c.6.12.83-.26.83-.57L9 21.07c-3.34.72-4.04-1.61-4.04-1.61-.55-1.39-1.34-1.76-1.34-1.76-1.08-.74.09-.73.09-.73 1.2.09 1.83 1.24 1.83 1.24 1.08 1.83 2.81 1.3 3.5 1 .1-.78.42-1.31.76-1.61-2.67-.3-5.47-1.33-5.47-5.93 0-1.31.47-2.38 1.24-3.22-.14-.3-.54-1.52.1-3.18 0 0 1-.32 3.3 1.23a11.5 11.5 0 0 1 6 0c2.28-1.55 3.29-1.23 3.29-1.23.64 1.66.24 2.88.12 3.18a4.65 4.65 0 0 1 1.23 3.22c0 4.61-2.8 5.63-5.48 5.92.42.36.81 1.1.81 2.22l-.01 3.29c0 .31.2.69.82.57A12 12 0 0 0 12 .3Z"/></svg></a><a href="https://discord.com/invite/binzhango" rel="me" class="sl-flex astro-wy4te6ga"><span class="sr-only astro-wy4te6ga">Discord</span><svg aria-hidden="true" class="astro-wy4te6ga astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M20.32 4.37a19.8 19.8 0 0 0-4.93-1.51 13.78 13.78 0 0 0-.64 1.28 18.27 18.27 0 0 0-5.5 0 12.64 12.64 0 0 0-.64-1.28h-.05A19.74 19.74 0 0 0 3.64 4.4 20.26 20.26 0 0 0 .11 18.09l.02.02a19.9 19.9 0 0 0 6.04 3.03l.04-.02a14.24 14.24 0 0 0 1.23-2.03.08.08 0 0 0-.05-.07 13.1 13.1 0 0 1-1.9-.92.08.08 0 0 1 .02-.1 10.2 10.2 0 0 0 .41-.31h.04a14.2 14.2 0 0 0 12.1 0l.04.01a9.63 9.63 0 0 0 .4.32.08.08 0 0 1-.03.1 12.29 12.29 0 0 1-1.9.91.08.08 0 0 0-.02.1 15.97 15.97 0 0 0 1.27 2.01h.04a19.84 19.84 0 0 0 6.03-3.05v-.03a20.12 20.12 0 0 0-3.57-13.69ZM8.02 15.33c-1.18 0-2.16-1.08-2.16-2.42 0-1.33.96-2.42 2.16-2.42 1.21 0 2.18 1.1 2.16 2.42 0 1.34-.96 2.42-2.16 2.42Zm7.97 0c-1.18 0-2.15-1.08-2.15-2.42 0-1.33.95-2.42 2.15-2.42 1.22 0 2.18 1.1 2.16 2.42 0 1.34-.94 2.42-2.16 2.42Z"/></svg></a><a href="https://www.threads.net/@binzhango" rel="me" class="sl-flex astro-wy4te6ga"><span class="sr-only astro-wy4te6ga">Threads</span><svg aria-hidden="true" class="astro-wy4te6ga astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="m17.73 11.2-.29-.13c-.17-3.13-1.88-4.92-4.75-4.94h-.04c-1.72 0-3.14.73-4.02 2.06l1.58 1.09a2.8 2.8 0 0 1 2.47-1.21c.94 0 1.66.28 2.12.81.33.4.56.93.67 1.61-.84-.14-1.74-.18-2.71-.13-2.73.16-4.49 1.75-4.37 3.97a3.41 3.41 0 0 0 1.57 2.71c.81.54 1.85.8 2.93.74a4.32 4.32 0 0 0 3.33-1.62 6 6 0 0 0 1.14-2.97 3.5 3.5 0 0 1 1.46 1.6 4 4 0 0 1-.98 4.4c-1.3 1.3-2.86 1.85-5.21 1.87-2.62-.02-4.6-.86-5.88-2.5-1.2-1.52-1.82-3.73-1.85-6.56.03-2.83.65-5.04 1.85-6.57 1.29-1.63 3.26-2.47 5.88-2.49 2.63.02 4.64.86 5.97 2.5.66.8 1.15 1.82 1.48 3l1.85-.5c-.4-1.44-1.02-2.7-1.86-3.73-1.71-2.1-4.21-3.19-7.44-3.21h-.01c-3.22.02-5.7 1.1-7.35 3.22C3.79 6.1 3.03 8.72 3 11.99V12c.03 3.29.79 5.9 2.27 7.78 1.66 2.12 4.13 3.2 7.35 3.22h.01c2.86-.02 4.88-.77 6.54-2.43a5.95 5.95 0 0 0 1.4-6.56 5.62 5.62 0 0 0-2.84-2.81Zm-4.94 4.64c-1.2.07-2.44-.47-2.5-1.62-.05-.85.6-1.8 2.57-1.92l.67-.02c.71 0 1.38.07 1.99.2-.23 2.84-1.56 3.3-2.73 3.36Z"/></svg></a> </div> </div> </div> </div> </header> <nav class="sidebar print:hidden astro-vrdttmbt" aria-label="Main"> <starlight-menu-button class="print:hidden astro-jif73yzw"> <button aria-expanded="false" aria-label="Menu" aria-controls="starlight__sidebar" class="sl-flex md:sl-hidden astro-jif73yzw"> <svg aria-hidden="true" class="open-menu astro-jif73yzw astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M3 8h18a1 1 0 1 0 0-2H3a1 1 0 0 0 0 2Zm18 8H3a1 1 0 0 0 0 2h18a1 1 0 0 0 0-2Zm0-5H3a1 1 0 0 0 0 2h18a1 1 0 0 0 0-2Z"/></svg> <svg aria-hidden="true" class="close-menu astro-jif73yzw astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="m13.41 12 6.3-6.29a1.004 1.004 0 1 0-1.42-1.42L12 10.59l-6.29-6.3a1.004 1.004 0 0 0-1.42 1.42l6.3 6.29-6.3 6.29a1 1 0 0 0 0 1.42.998.998 0 0 0 1.42 0l6.29-6.3 6.29 6.3a.999.999 0 0 0 1.42 0 1 1 0 0 0 0-1.42L13.41 12Z"/></svg> </button> </starlight-menu-button> <script type="module">class s extends HTMLElement{constructor(){super(),this.btn=this.querySelector("button"),this.btn.addEventListener("click",()=>this.toggleExpanded());const t=this.closest("nav");t&&t.addEventListener("keyup",e=>this.closeOnEscape(e))}setExpanded(t){this.setAttribute("aria-expanded",String(t)),document.body.toggleAttribute("data-mobile-menu-expanded",t)}toggleExpanded(){this.setExpanded(this.getAttribute("aria-expanded")!=="true")}closeOnEscape(t){t.code==="Escape"&&(this.setExpanded(!1),this.btn.focus())}}customElements.define("starlight-menu-button",s);</script>   <div id="starlight__sidebar" class="sidebar-pane astro-vrdttmbt"> <div class="sidebar-content sl-flex astro-vrdttmbt"> <sl-sidebar-state-persist data-hash="0puq9sp" class="astro-kku4brbg"> <script aria-hidden="true">
		(() => {
			try {
				if (!matchMedia('(min-width: 50em)').matches) return;
				/** @type {HTMLElement | null} */
				const target = document.querySelector('sl-sidebar-state-persist');
				const state = JSON.parse(sessionStorage.getItem('sl-sidebar-state') || '0');
				if (!target || !state || target.dataset.hash !== state.hash) return;
				window._starlightScrollRestore = state.scroll;
				customElements.define(
					'sl-sidebar-restore',
					class SidebarRestore extends HTMLElement {
						connectedCallback() {
							try {
								const idx = parseInt(this.dataset.index || '');
								const details = this.closest('details');
								if (details && typeof state.open[idx] === 'boolean') details.open = state.open[idx];
							} catch {}
						}
					}
				);
			} catch {}
		})();
	</script>  <ul class="top-level astro-3ii7xxms"> <li class="astro-3ii7xxms"> <details open class="astro-3ii7xxms"> <summary class="astro-3ii7xxms"> <span class="group-label astro-3ii7xxms"> <span class="large astro-3ii7xxms">2026</span>  </span> <svg aria-hidden="true" class="caret astro-3ii7xxms astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1.25rem;"><path d="m14.83 11.29-4.24-4.24a1 1 0 1 0-1.42 1.41L12.71 12l-3.54 3.54a1 1 0 0 0 0 1.41 1 1 0 0 0 .71.29 1 1 0 0 0 .71-.29l4.24-4.24a1.002 1.002 0 0 0 0-1.42Z"/></svg> </summary> <sl-sidebar-restore data-index="0"></sl-sidebar-restore> <ul class="astro-3ii7xxms"> <li class="astro-3ii7xxms"> <a href="/posts/2026/02-01-test-mdx" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Test MDX Blog Post</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2026/01-04-chatgpt-2025-summary" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">ChatGPT in 2025: A Year in Review</span>  </a> </li> </ul>  </details> </li><li class="astro-3ii7xxms"> <details open class="astro-3ii7xxms"> <summary class="astro-3ii7xxms"> <span class="group-label astro-3ii7xxms"> <span class="large astro-3ii7xxms">2025</span>  </span> <svg aria-hidden="true" class="caret astro-3ii7xxms astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1.25rem;"><path d="m14.83 11.29-4.24-4.24a1 1 0 1 0-1.42 1.41L12.71 12l-3.54 3.54a1 1 0 0 0 0 1.41 1 1 0 0 0 .71.29 1 1 0 0 0 .71-.29l4.24-4.24a1.002 1.002 0 0 0 0-1.42Z"/></svg> </summary> <sl-sidebar-restore data-index="1"></sl-sidebar-restore> <ul class="astro-3ii7xxms"> <li class="astro-3ii7xxms"> <a href="/posts/2025/11-27-ai-engineer" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">The Mandate for Leadership in AI Engineering</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/10-30-llm-interview" aria-current="page" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">LLM Interview Questions</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/10-29-epoch" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">LLM Training Epoch</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/10-20-vllm" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">vllm throughput</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/10-19-reflection" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">LangGraph Reflection</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/10-02-langchain" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">LangGraph Sample Project</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/09-29-langchain" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">LangChain/LangGraph Q&amp;A</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/08-10-model-training" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Training LLM From Zero</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/07-16-fastmcp-mcp-server" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">FastMCP MCP Server Hub</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/07-11-llm-tools" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">How LLM Tools work</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/07-01-langchain-retry" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">LangChain Retry Logic</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/06-23-mcp-transports" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">MCP Transports</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/05-04-text-to-sql" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Text to SQL (Smolagents)</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/04-25-mcp" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">MCP Server &amp; Client (SSE)</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/04-22-reranking-in-rag" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">RAG-Reranking</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/04-21-ollama-gguf" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Ollama Import GGUF Models</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/03-29-llm-usage" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">GenAI Projects</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/02-16-web-crawler" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Crawling the Web with LLM</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/02-09-langgraph-autogen" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">LangGraph VS AutoGen</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/02-08-autogen" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Autogen Intro and RAG Workflow</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2025/02-02-local-llm-model-setup" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Local LLM Setup</span>  </a> </li> </ul>  </details> </li><li class="astro-3ii7xxms"> <details class="astro-3ii7xxms"> <summary class="astro-3ii7xxms"> <span class="group-label astro-3ii7xxms"> <span class="large astro-3ii7xxms">2024</span>  </span> <svg aria-hidden="true" class="caret astro-3ii7xxms astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1.25rem;"><path d="m14.83 11.29-4.24-4.24a1 1 0 1 0-1.42 1.41L12.71 12l-3.54 3.54a1 1 0 0 0 0 1.41 1 1 0 0 0 .71.29 1 1 0 0 0 .71-.29l4.24-4.24a1.002 1.002 0 0 0 0-1.42Z"/></svg> </summary> <sl-sidebar-restore data-index="2"></sl-sidebar-restore> <ul class="astro-3ii7xxms"> <li class="astro-3ii7xxms"> <a href="/posts/2024/12-15-gradio-with-llm" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Gradio with Ollama</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2024/11-15-pyspark-usage" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">PySpark Dataframe Transformation</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2024/11-01-databricks-pyspark-wheel-project" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Databricks Wheel Job</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2024/10-23-python-decorator" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Python Decorator</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2024/10-16-zio" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">ZIO</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2024/10-13-reflex-learning-youtube" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Reflex Learning</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/2024/01-01-autogen-reset-client" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">AutoGen HttpClient</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/how-to-execute-python-module" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">How to execute python modules</span>  </a> </li> </ul>  </details> </li><li class="astro-3ii7xxms"> <details class="astro-3ii7xxms"> <summary class="astro-3ii7xxms"> <span class="group-label astro-3ii7xxms"> <span class="large astro-3ii7xxms">2020</span>  </span> <svg aria-hidden="true" class="caret astro-3ii7xxms astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1.25rem;"><path d="m14.83 11.29-4.24-4.24a1 1 0 1 0-1.42 1.41L12.71 12l-3.54 3.54a1 1 0 0 0 0 1.41 1 1 0 0 0 .71.29 1 1 0 0 0 .71-.29l4.24-4.24a1.002 1.002 0 0 0 0-1.42Z"/></svg> </summary> <sl-sidebar-restore data-index="3"></sl-sidebar-restore> <ul class="astro-3ii7xxms"> <li class="astro-3ii7xxms"> <a href="/posts/whitening-transformation" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Whitening transformation</span>  </a> </li> </ul>  </details> </li><li class="astro-3ii7xxms"> <details class="astro-3ii7xxms"> <summary class="astro-3ii7xxms"> <span class="group-label astro-3ii7xxms"> <span class="large astro-3ii7xxms">2012</span>  </span> <svg aria-hidden="true" class="caret astro-3ii7xxms astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1.25rem;"><path d="m14.83 11.29-4.24-4.24a1 1 0 1 0-1.42 1.41L12.71 12l-3.54 3.54a1 1 0 0 0 0 1.41 1 1 0 0 0 .71.29 1 1 0 0 0 .71-.29l4.24-4.24a1.002 1.002 0 0 0 0-1.42Z"/></svg> </summary> <sl-sidebar-restore data-index="4"></sl-sidebar-restore> <ul class="astro-3ii7xxms"> <li class="astro-3ii7xxms"> <a href="/posts/repos" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Repo List</span>  </a> </li> </ul>  </details> </li><li class="astro-3ii7xxms"> <details class="astro-3ii7xxms"> <summary class="astro-3ii7xxms"> <span class="group-label astro-3ii7xxms"> <span class="large astro-3ii7xxms">NaN</span>  </span> <svg aria-hidden="true" class="caret astro-3ii7xxms astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1.25rem;"><path d="m14.83 11.29-4.24-4.24a1 1 0 1 0-1.42 1.41L12.71 12l-3.54 3.54a1 1 0 0 0 0 1.41 1 1 0 0 0 .71.29 1 1 0 0 0 .71-.29l4.24-4.24a1.002 1.002 0 0 0 0-1.42Z"/></svg> </summary> <sl-sidebar-restore data-index="5"></sl-sidebar-restore> <ul class="astro-3ii7xxms"> <li class="astro-3ii7xxms"> <a href="/posts/airflow" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Airflow</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/azure-data-factory-data-flow" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Azure Data Factory (Data Flow)</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/batch-normalization" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Batch Normalization</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/gradient-descent" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Gradient Descent</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/minikube-in-macos" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Setup Minikube</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/model-registry" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Model Registry</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/snowflake_training_summary" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Snowflake Data Science Training Summary</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/spark-dataframe-window-function" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Spark Dataframe window function</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/spark-optimization" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Spark Optimization</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/spark-structured-streaming" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Spark Structured Streaming</span>  </a> </li><li class="astro-3ii7xxms"> <a href="/posts/sparksql_tuning" class="astro-3ii7xxms"> <span class="astro-3ii7xxms">Spark SQL</span>  </a> </li> </ul>  </details> </li> </ul>   <script aria-hidden="true">
		(() => {
			const scroller = document.getElementById('starlight__sidebar');
			if (!window._starlightScrollRestore || !scroller) return;
			scroller.scrollTop = window._starlightScrollRestore;
			delete window._starlightScrollRestore;
		})();
	</script> </sl-sidebar-state-persist>  <div class="md:sl-hidden"> <div class="mobile-preferences sl-flex astro-wu23bvmt"> <div class="social-icons astro-wu23bvmt"> <a href="https://github.com/binzhango" rel="me" class="sl-flex astro-wy4te6ga"><span class="sr-only astro-wy4te6ga">GitHub</span><svg aria-hidden="true" class="astro-wy4te6ga astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M12 .3a12 12 0 0 0-3.8 23.38c.6.12.83-.26.83-.57L9 21.07c-3.34.72-4.04-1.61-4.04-1.61-.55-1.39-1.34-1.76-1.34-1.76-1.08-.74.09-.73.09-.73 1.2.09 1.83 1.24 1.83 1.24 1.08 1.83 2.81 1.3 3.5 1 .1-.78.42-1.31.76-1.61-2.67-.3-5.47-1.33-5.47-5.93 0-1.31.47-2.38 1.24-3.22-.14-.3-.54-1.52.1-3.18 0 0 1-.32 3.3 1.23a11.5 11.5 0 0 1 6 0c2.28-1.55 3.29-1.23 3.29-1.23.64 1.66.24 2.88.12 3.18a4.65 4.65 0 0 1 1.23 3.22c0 4.61-2.8 5.63-5.48 5.92.42.36.81 1.1.81 2.22l-.01 3.29c0 .31.2.69.82.57A12 12 0 0 0 12 .3Z"/></svg></a><a href="https://discord.com/invite/binzhango" rel="me" class="sl-flex astro-wy4te6ga"><span class="sr-only astro-wy4te6ga">Discord</span><svg aria-hidden="true" class="astro-wy4te6ga astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M20.32 4.37a19.8 19.8 0 0 0-4.93-1.51 13.78 13.78 0 0 0-.64 1.28 18.27 18.27 0 0 0-5.5 0 12.64 12.64 0 0 0-.64-1.28h-.05A19.74 19.74 0 0 0 3.64 4.4 20.26 20.26 0 0 0 .11 18.09l.02.02a19.9 19.9 0 0 0 6.04 3.03l.04-.02a14.24 14.24 0 0 0 1.23-2.03.08.08 0 0 0-.05-.07 13.1 13.1 0 0 1-1.9-.92.08.08 0 0 1 .02-.1 10.2 10.2 0 0 0 .41-.31h.04a14.2 14.2 0 0 0 12.1 0l.04.01a9.63 9.63 0 0 0 .4.32.08.08 0 0 1-.03.1 12.29 12.29 0 0 1-1.9.91.08.08 0 0 0-.02.1 15.97 15.97 0 0 0 1.27 2.01h.04a19.84 19.84 0 0 0 6.03-3.05v-.03a20.12 20.12 0 0 0-3.57-13.69ZM8.02 15.33c-1.18 0-2.16-1.08-2.16-2.42 0-1.33.96-2.42 2.16-2.42 1.21 0 2.18 1.1 2.16 2.42 0 1.34-.96 2.42-2.16 2.42Zm7.97 0c-1.18 0-2.15-1.08-2.15-2.42 0-1.33.95-2.42 2.15-2.42 1.22 0 2.18 1.1 2.16 2.42 0 1.34-.94 2.42-2.16 2.42Z"/></svg></a><a href="https://www.threads.net/@binzhango" rel="me" class="sl-flex astro-wy4te6ga"><span class="sr-only astro-wy4te6ga">Threads</span><svg aria-hidden="true" class="astro-wy4te6ga astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="m17.73 11.2-.29-.13c-.17-3.13-1.88-4.92-4.75-4.94h-.04c-1.72 0-3.14.73-4.02 2.06l1.58 1.09a2.8 2.8 0 0 1 2.47-1.21c.94 0 1.66.28 2.12.81.33.4.56.93.67 1.61-.84-.14-1.74-.18-2.71-.13-2.73.16-4.49 1.75-4.37 3.97a3.41 3.41 0 0 0 1.57 2.71c.81.54 1.85.8 2.93.74a4.32 4.32 0 0 0 3.33-1.62 6 6 0 0 0 1.14-2.97 3.5 3.5 0 0 1 1.46 1.6 4 4 0 0 1-.98 4.4c-1.3 1.3-2.86 1.85-5.21 1.87-2.62-.02-4.6-.86-5.88-2.5-1.2-1.52-1.82-3.73-1.85-6.56.03-2.83.65-5.04 1.85-6.57 1.29-1.63 3.26-2.47 5.88-2.49 2.63.02 4.64.86 5.97 2.5.66.8 1.15 1.82 1.48 3l1.85-.5c-.4-1.44-1.02-2.7-1.86-3.73-1.71-2.1-4.21-3.19-7.44-3.21h-.01c-3.22.02-5.7 1.1-7.35 3.22C3.79 6.1 3.03 8.72 3 11.99V12c.03 3.29.79 5.9 2.27 7.78 1.66 2.12 4.13 3.2 7.35 3.22h.01c2.86-.02 4.88-.77 6.54-2.43a5.95 5.95 0 0 0 1.4-6.56 5.62 5.62 0 0 0-2.84-2.81Zm-4.94 4.64c-1.2.07-2.44-.47-2.5-1.62-.05-.85.6-1.8 2.57-1.92l.67-.02c.71 0 1.38.07 1.99.2-.23 2.84-1.56 3.3-2.73 3.36Z"/></svg></a> </div> <starlight-theme-select>  <label style="--sl-select-width: 6.25em" class="astro-4yphtoen"> <span class="sr-only astro-4yphtoen">Select theme</span> <svg aria-hidden="true" class="icon label-icon astro-4yphtoen astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M21 14h-1V7a3 3 0 0 0-3-3H7a3 3 0 0 0-3 3v7H3a1 1 0 0 0-1 1v2a3 3 0 0 0 3 3h14a3 3 0 0 0 3-3v-2a1 1 0 0 0-1-1ZM6 7a1 1 0 0 1 1-1h10a1 1 0 0 1 1 1v7H6V7Zm14 10a1 1 0 0 1-1 1H5a1 1 0 0 1-1-1v-1h16v1Z"/></svg> <select autocomplete="off" class="astro-4yphtoen"> <option value="dark" class="astro-4yphtoen">Dark</option><option value="light" class="astro-4yphtoen">Light</option><option value="auto" selected class="astro-4yphtoen">Auto</option> </select> <svg aria-hidden="true" class="icon caret astro-4yphtoen astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M17 9.17a1 1 0 0 0-1.41 0L12 12.71 8.46 9.17a1 1 0 1 0-1.41 1.42l4.24 4.24a1.002 1.002 0 0 0 1.42 0L17 10.59a1.002 1.002 0 0 0 0-1.42Z"/></svg> </label>  </starlight-theme-select>  <script>
	StarlightThemeProvider.updatePickers();
</script> <script type="module">const r="starlight-theme",o=e=>e==="auto"||e==="dark"||e==="light"?e:"auto",c=()=>o(typeof localStorage<"u"&&localStorage.getItem(r));function n(e){typeof localStorage<"u"&&localStorage.setItem(r,e==="light"||e==="dark"?e:"")}const l=()=>matchMedia("(prefers-color-scheme: light)").matches?"light":"dark";function t(e){StarlightThemeProvider.updatePickers(e),document.documentElement.dataset.theme=e==="auto"?l():e,n(e)}matchMedia("(prefers-color-scheme: light)").addEventListener("change",()=>{c()==="auto"&&t("auto")});class s extends HTMLElement{constructor(){super(),t(c()),this.querySelector("select")?.addEventListener("change",a=>{a.currentTarget instanceof HTMLSelectElement&&t(o(a.currentTarget.value))})}}customElements.define("starlight-theme-select",s);</script> <script type="module">class s extends HTMLElement{constructor(){super();const e=this.querySelector("select");e&&(e.addEventListener("change",t=>{t.currentTarget instanceof HTMLSelectElement&&(window.location.pathname=t.currentTarget.value)}),window.addEventListener("pageshow",t=>{if(!t.persisted)return;const n=e.querySelector("option[selected]")?.index;n!==e.selectedIndex&&(e.selectedIndex=n??0)}))}}customElements.define("starlight-lang-select",s);</script> </div>  </div> </div> </div> </nav> <div class="main-frame astro-vrdttmbt">  <script type="module">const a=document.getElementById("starlight__sidebar"),n=a?.querySelector("sl-sidebar-state-persist"),o="sl-sidebar-state",i=()=>{let t=[];const e=n?.dataset.hash||"";try{const s=sessionStorage.getItem(o),r=JSON.parse(s||"{}");Array.isArray(r.open)&&r.hash===e&&(t=r.open)}catch{}return{hash:e,open:t,scroll:a?.scrollTop||0}},c=t=>{try{sessionStorage.setItem(o,JSON.stringify(t))}catch{}},d=()=>c(i()),l=(t,e)=>{const s=i();s.open[e]=t,c(s)};n?.addEventListener("click",t=>{if(!(t.target instanceof Element))return;const e=t.target.closest("summary")?.closest("details");if(!e)return;const s=e.querySelector("sl-sidebar-restore"),r=parseInt(s?.dataset.index||"");isNaN(r)||l(!e.open,r)});addEventListener("visibilitychange",()=>{document.visibilityState==="hidden"&&d()});addEventListener("pageHide",d);</script> <div class="lg:sl-flex astro-67yu43on"> <aside class="right-sidebar-container print:hidden astro-67yu43on"> <div class="right-sidebar astro-67yu43on"> <script type="module" src="/_astro/MobileTableOfContents.astro_astro_type_script_index_0_lang.hwBsy0Mo.js"></script><script type="module" src="/_astro/TableOfContents.astro_astro_type_script_index_0_lang.FuRcXuRY.js"></script><div class="lg:sl-hidden astro-pb3aqygn"><mobile-starlight-toc data-min-h="2" data-max-h="3" class="astro-doynk5tl"><nav aria-labelledby="starlight__on-this-page--mobile" class="astro-doynk5tl"><details id="starlight__mobile-toc" class="astro-doynk5tl"><summary id="starlight__on-this-page--mobile" class="sl-flex astro-doynk5tl"><span class="toggle sl-flex astro-doynk5tl">On this page<svg aria-hidden="true" class="caret astro-doynk5tl astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1rem;"><path d="m14.83 11.29-4.24-4.24a1 1 0 1 0-1.42 1.41L12.71 12l-3.54 3.54a1 1 0 0 0 0 1.41 1 1 0 0 0 .71.29 1 1 0 0 0 .71-.29l4.24-4.24a1.002 1.002 0 0 0 0-1.42Z"/></svg></span><span class="display-current astro-doynk5tl"></span></summary><div class="dropdown astro-doynk5tl"><ul class="isMobile astro-g2bywc46" style="--depth: 0;"> <li class="astro-g2bywc46" style="--depth: 0;"> <a href="#_top" class="astro-g2bywc46" style="--depth: 0;"> <span class="astro-g2bywc46" style="--depth: 0;">Overview</span> </a>  </li><li class="astro-g2bywc46" style="--depth: 0;"> <a href="#machine-learning" class="astro-g2bywc46" style="--depth: 0;"> <span class="astro-g2bywc46" style="--depth: 0;">Machine Learning</span> </a>  </li><li class="astro-g2bywc46" style="--depth: 0;"> <a href="#llm-fundamentals" class="astro-g2bywc46" style="--depth: 0;"> <span class="astro-g2bywc46" style="--depth: 0;">LLM Fundamentals</span> </a>  </li><li class="astro-g2bywc46" style="--depth: 0;"> <a href="#fundamentals-of-large-language-models-llms" class="astro-g2bywc46" style="--depth: 0;"> <span class="astro-g2bywc46" style="--depth: 0;">Fundamentals of Large Language Models (LLMs)</span> </a>  </li> </ul> </div></details></nav></mobile-starlight-toc></div><div class="right-sidebar-panel sl-hidden lg:sl-block astro-pb3aqygn"><div class="sl-container astro-pb3aqygn"><starlight-toc data-min-h="2" data-max-h="3"><nav aria-labelledby="starlight__on-this-page"><h2 id="starlight__on-this-page">On this page</h2><ul class="astro-g2bywc46" style="--depth: 0;"> <li class="astro-g2bywc46" style="--depth: 0;"> <a href="#_top" class="astro-g2bywc46" style="--depth: 0;"> <span class="astro-g2bywc46" style="--depth: 0;">Overview</span> </a>  </li><li class="astro-g2bywc46" style="--depth: 0;"> <a href="#machine-learning" class="astro-g2bywc46" style="--depth: 0;"> <span class="astro-g2bywc46" style="--depth: 0;">Machine Learning</span> </a>  </li><li class="astro-g2bywc46" style="--depth: 0;"> <a href="#llm-fundamentals" class="astro-g2bywc46" style="--depth: 0;"> <span class="astro-g2bywc46" style="--depth: 0;">LLM Fundamentals</span> </a>  </li><li class="astro-g2bywc46" style="--depth: 0;"> <a href="#fundamentals-of-large-language-models-llms" class="astro-g2bywc46" style="--depth: 0;"> <span class="astro-g2bywc46" style="--depth: 0;">Fundamentals of Large Language Models (LLMs)</span> </a>  </li> </ul> </nav></starlight-toc></div></div> </div> </aside> <div class="main-pane astro-67yu43on">  <main data-pagefind-body class="astro-bguv2lll" lang="en" dir="ltr">   <script type="module">function i(){const t=document.querySelector(".back-to-top"),e=document.querySelector(".header-wrapper");if(!t)return;let l=window.scrollY,s=!1;function n(){const o=window.scrollY;o>300?t.classList.add("visible"):t.classList.remove("visible"),e&&(o>l&&o>100?e.classList.add("hidden"):e.classList.remove("hidden"),o>10?e.classList.add("scrolled"):e.classList.remove("scrolled")),l=o,s=!1}function d(){s||(window.requestAnimationFrame(n),s=!0)}function c(){window.scrollTo({top:0,behavior:"smooth"})}window.addEventListener("scroll",d,{passive:!0}),t.addEventListener("click",c),n()}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",i):i();document.addEventListener("astro:page-load",i);</script> <div class="content-panel astro-7nkwcw3z"> <div class="sl-container astro-7nkwcw3z"> <h1 id="_top" class="astro-j6tvhyss">LLM Interview Questions</h1>  </div> </div> <button class="back-to-top" aria-label="Back to top" title="Back to top"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor"> <path d="M12 4l-8 8h5v8h6v-8h5z"></path> </svg> </button>  <div class="content-panel astro-zcendh45"><div class="sl-container astro-zcendh45"><div class="post-metadata-inline astro-zcendh45"><span class="metadata-item astro-zcendh45"><span class="metadata-label astro-zcendh45">author:</span><span class="metadata-value astro-zcendh45">BZ</span></span><span class="metadata-item astro-zcendh45"><span class="metadata-label astro-zcendh45">date:</span><span class="metadata-value astro-zcendh45">2025-10-30</span></span></div> <div class="sl-markdown-content"> <div class="sl-heading-wrapper level-h1"><h1 id="questions">Questions</h1><a class="sl-anchor-link" href="#questions"><span aria-hidden="true" class="sl-anchor-icon"><svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path></svg></span><span class="sr-only" data-pagefind-ignore="">Section titled â€œQuestionsâ€</span></a></div>
<!-- more -->
<div class="sl-heading-wrapper level-h2"><h2 id="machine-learning">Machine Learning</h2><a class="sl-anchor-link" href="#machine-learning"><span aria-hidden="true" class="sl-anchor-icon"><svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path></svg></span><span class="sr-only" data-pagefind-ignore="">Section titled â€œMachine Learningâ€</span></a></div>
<p>??? tip â€œMachine Learning Conceptsâ€</p>
<div class="expressive-code"><link rel="stylesheet" href="/_astro/ec.8jbm5.css"><script type="module" src="/_astro/ec.g1fg5.js"></script><figure class="frame not-content"><figcaption class="header"></figcaption><pre data-language="plaintext" class="wrap" style="--ecMaxLine:429ch"><code><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">1</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "How would you describe the concept of machine learning in your own words?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">2</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">3</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">Machine learning focuses on creating systems that improve their performance on a task by learning patterns from data rather than relying on explicit programming.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">4</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">5</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "Can you give a few examples of real-world areas where machine learning is particularly effective?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">6</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">7</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">Machine learning is especially valuable for solving complex problems without clear rule-based solutions, automating decision-making instead of hand-crafted logic, adapting to changing environments, and extracting insights from large datasets.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">8</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">9</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">10</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "What are some typical problems addressed with unsupervised learning methods?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">11</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">12</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">Typical unsupervised learning tasks include clustering, data visualization, dimensionality reduction, and association rule mining.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">13</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">14</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">15</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "Would detecting spam emails be treated as a supervised or unsupervised learning problem, and why?"</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">16</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">Spam filtering is an example of a supervised learning problem because the model learns from examples of emails labeled as "spam" or "not spam".</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">17</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">18</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">19</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "What does the term â€˜out-of-core learningâ€™ refer to in machine learning?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">20</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">21</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">Out-of-core learning enables training on datasets too large to fit in memory by processing them in smaller chunks (mini-batches) and updating the model incrementally.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">22</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">23</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">24</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "How can you distinguish between model parameters and hyperparameters?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">25</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">26</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Model parameters** define how the model behaves and are learned during training (e.g., weights in linear regression).</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">27</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">28</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Hyperparameters** are external settings chosen before training, such as the learning rate or regularization strength.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">29</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">30</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">31</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "What are some major difficulties or limitations commonly faced when building machine learning systems?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">32</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:6ch"><div class="gutter"><div class="ln" aria-hidden="true">33</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">      </span></span><span style="--0:#e1e4e8;--1:#24292e">Key challenges in machine learning include</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">34</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">35</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- insufficient or low-quality data</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">36</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- poor feature selection</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">37</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- non-representative samples</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">38</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- models that either underfit (too simple) or overfit (too complex)</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">39</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">40</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "If a model performs well on training data but poorly on unseen data, what issue is occurring, and how might you address it?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">41</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">42</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">When a model performs well on training data but poorly on unseen examples, itâ€™s overfitting. This can be mitigated by collecting more diverse data, simplifying the model, applying regularization, or cleaning noisy data.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">43</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">44</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "What is a test dataset used for, and why is it essential in evaluating a modelâ€™s performance?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">45</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">46</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">A test set provides an unbiased estimate of how well a model will perform on new, real-world data before deployment.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">47</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">48</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "What role does a validation set play during the model development process?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">49</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">50</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">A validation set helps compare multiple models and tune hyperparameters, ensuring better generalization to unseen data.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">51</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">52</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "What is a train-dev dataset, in what situations would you create one, and how is it applied during model evaluation?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">53</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">54</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">The train-dev set is a small portion of the training data set aside to identify mismatches between the training distribution and the validation/test distributions. You use it when you suspect that your production data may differ from your training data. The model is trained on most of the training data and evaluated on the train-dev set to detect overfitting or data mismatch before comparing results on the validation set.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">55</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">56</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? question "Why is it problematic to adjust hyperparameters based on test set performance?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">57</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">58</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">If you tune hyperparameters using the test set, you risk overfitting to that specific test data, making your performance results misleadingly high. As a result, the model might perform worse in real-world scenarios because the test set is no longer an unbiased measure of generalization.</span></div></div></code></pre></figure></div>
<div class="sl-heading-wrapper level-h2"><h2 id="llm-fundamentals">LLM Fundamentals</h2><a class="sl-anchor-link" href="#llm-fundamentals"><span aria-hidden="true" class="sl-anchor-icon"><svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path></svg></span><span class="sr-only" data-pagefind-ignore="">Section titled â€œLLM Fundamentalsâ€</span></a></div>
<p>??? question â€œExplain bias-variance tradeoff. How does it manifest in LLMs?â€</p>
<div class="expressive-code"><figure class="frame not-content"><figcaption class="header"></figcaption><pre data-language="plaintext" class="wrap" style="--ecMaxLine:213ch"><code><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">1</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">Bias&#x3C;/span>: Error from incorrect assumption in the model</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">2</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- High bias leads to underfitting, where the model fails to capture patterns in the training data</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">3</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">4</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">Variance&#x3C;/span>: Error from sensitivity to small fluctuations in the training data</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">5</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- High variance leads to overfitting, where the model memorizes noise instead of learning generalization patterns</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">6</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">7</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">8</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">The bias-variance tradeoff in ML describe the tension between **ability to fit training data** and **ability to generalize the new data**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">9</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">10</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">&#x3C;span class="def-mono-blue">bias-variance in LLM&#x3C;/span>:</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">11</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">12</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-gold">Model Parameters: Capacity vs. Overfitting&#x3C;/span></span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">13</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Too few parameters**: A model with insufficient (e.g. small transformer) cannot capture complex patterns in the data, leading to high bias.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">14</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> A small LLM might fail to understand language or generate coherent long texts.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">15</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Too many parameters**: A model with excessive capacity risks overfitting to training data, memorizing noise and details instead of learning generalizable patterns</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">16</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> A large LLM fine-tuned on a small dataset may generate text that is statistically similar to the training data but lack coherence and factual accuracy. (e.g. &#x3C;span class="def-mono-red">hallucinations&#x3C;/span>)</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">17</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Balancing Act**:</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">18</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> More parameters reduce bias by enabling the model to capture complex patterns but increase variance if not regularized.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">19</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> Regularization techniques: (e.g dropout, weight decay) help mitigate overfitting in high-parameter models</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">20</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">21</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-gold">Training Epochs: Learning Duration vs. Overfitting&#x3C;/span></span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">22</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Too few epochs**: The model hasn't learned enough from the data, leading to high bias.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">23</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> A transformer trained for only 1 epoch may fail to capture meaningful relationships in the text.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">24</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Too many epochs**: The model starts memorizing training data, increasing variance. This is common in transformer with high capacity and small datasets</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">25</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> A transformer fine-tuned on a medical dataset for 100 epochs may overfit to rare cases, leading to poor generalization.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">26</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Tradeoff in Transformers**</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">27</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> Training loss decreases with epochs (low bias), but validation loss eventually increase (high variance).</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">28</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">29</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> Early stopping is critical for transformers to avoid overfitting, especially when training on small or noisy datasets.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">30</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-gold">Noise vs Representativeness &#x3C;/span></span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">31</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Low-quality data**: Noisy, biased, or incomplete data prevents the model from learning accurate patterns, increasing biase.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">32</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> A transformer trained on a dataset with limited examples of rare diseases may fail to diagnose them accurately</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">33</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Noisy/unrepresentative data**: The model learns inconsistent patterns, increasing variance.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">34</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> A dataset with duplicate or corrupted text may cause the model to overfit. A transformer trained on a dataset with biased political content</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">35</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> may generate polarized outputs.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">36</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">> Data augmentation (e.g. paraphrasing, back-translation) increases diversity, mitigating overfitting</span></div></div></code></pre></figure></div>
<p>??? question â€œWhat is the difference between L1 and L2 regularization? When would you use elastic net in an LLM fine-tune?â€</p>
<div class="expressive-code"><figure class="frame not-content"><figcaption class="header"></figcaption><pre data-language="plaintext" class="wrap" style="--ecMaxLine:151ch"><code><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">1</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">&#x3C;span class="def-mono-gold">Regularization&#x3C;/span> adds a penalty term to the loss function so that the optimizer favours simpler or smoother solutions.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">2</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">In practice it is usually added to a modelâ€‘level loss (crossâ€‘entropy, MSE, â€¦) as a separate scalar that scales with the weights.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">3</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">4</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">\[  \text{Loss}_{\text{regularized}} = \text{Loss}_{\text{original}} + \lambda \cdot \text{Penalty}(w) \]</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">5</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">6</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">|Feature | L1 (Lasso) | L2 (Ridge)|</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">7</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">|-:|:-:|:-:|</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">8</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">|Weight Behavior| Many â†’ 0 (sparse)|"All â†’ small, non-zero"|</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">9</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">|Feature Selection| Yes| No|</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">10</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">|Solution|Not always unique|Always unique|</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">11</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">|Robust to Outliers|Less|More|</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">12</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">13</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">&#x3C;span class="def-mono-red"> Key Insight:&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">14</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">15</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-blue">L1 regularization&#x3C;/span> is more robust to outliers in the **data (target outliers)**</span></div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">16</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-blue">L2 regularization&#x3C;/span> is more robust to outliers in the **features (collinearity)**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">17</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">18</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">&#x3C;span class="def-mono-red">L1/L2 in LLM&#x3C;/span>:</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">19</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">20</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">- Use L2 by default. Use L1 if you want sparse, interpretable updates.</span></div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">21</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">- L2 keeps updates smooth. L1 keeps updates minimal â€” and thatâ€™s often better for deployment.</span></div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">22</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">- Use L2 to win benchmarks. Use L1 to ship to users.</span></div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">23</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">> 1. Sparse LoRA = Tiny Adapters</span></div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">24</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">> 2. Faster Inference (Real Speedup!)</span></div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">25</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">> 3. Better Generalization (Less Overfitting)</span></div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">26</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">> 4. Interpretable Fine-Tuning</span></div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">27</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">> 5. Clean Model Merging</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">28</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">29</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">```sh</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">30</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">31</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">â”‚ Fine-tuning an LLM?  â”‚</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">32</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">33</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">â”‚</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">34</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">â–¼</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">35</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     YES â†’ Use L2 (weight_decay=0.01)</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">36</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">â”‚ Large, clean data?   â”‚â”€â”€â”€NOâ”€â”€â–ºâ”</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">37</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">38</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">â”‚                    â”‚</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">39</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">â–¼                    â–¼</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">40</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">41</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">â”‚ Need max accuracy?   â”‚ â”‚ Want small/fast model?   â”‚</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">42</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">43</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">â”‚                          â”‚</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">44</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">YES                        YES</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">45</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">â”‚                          â”‚</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">46</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">â–¼                          â–¼</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">47</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">Use L2                     Use L1 (+ pruning)</span></div></div><div class="ec-line" style="--ecIndent:2ch"><div class="gutter"><div class="ln" aria-hidden="true">48</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">  </span></span><span style="--0:#e1e4e8;--1:#24292e">```</span></div></div></code></pre></figure></div>
<p>??? question â€œProve that dropout is equivalent to an ensemble during inference (hint: geometric distribution).â€
- Where dropout appears in a Transformer
- Attention dropout
- Feedforward dropout
- Residual dropout
- The ensemble view of dropout in a Transformer
- Each layer (and even each neuron) may be dropped independently.
- A particular dropout mask <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="25.756ex" height="2.587ex" role="img" focusable="false" viewBox="0 -893.3 11384.3 1143.3" xmlns:xlink="http://www.w3.org/1999/xlink"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D45A" xlink:href="#MJX-TEX-I-1D45A"></use></g><g data-mml-node="mo" transform="translate(1155.8,0)"><use data-c="3D" xlink:href="#MJX-TEX-N-3D"></use></g><g data-mml-node="mo" transform="translate(2211.6,0)"><use data-c="28" xlink:href="#MJX-TEX-N-28"></use></g><g data-mml-node="msup" transform="translate(2600.6,0)"><g data-mml-node="mi"><use data-c="1D45A" xlink:href="#MJX-TEX-I-1D45A"></use></g><g data-mml-node="TeXAtom" transform="translate(911,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><use data-c="28" xlink:href="#MJX-TEX-N-28"></use></g><g data-mml-node="mn" transform="translate(389,0)"><use data-c="31" xlink:href="#MJX-TEX-N-31"></use></g><g data-mml-node="mo" transform="translate(889,0)"><use data-c="29" xlink:href="#MJX-TEX-N-29"></use></g></g></g><g data-mml-node="mo" transform="translate(4465.2,0)"><use data-c="2C" xlink:href="#MJX-TEX-N-2C"></use></g><g data-mml-node="msup" transform="translate(4909.9,0)"><g data-mml-node="mi"><use data-c="1D45A" xlink:href="#MJX-TEX-I-1D45A"></use></g><g data-mml-node="TeXAtom" transform="translate(911,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><use data-c="28" xlink:href="#MJX-TEX-N-28"></use></g><g data-mml-node="mn" transform="translate(389,0)"><use data-c="32" xlink:href="#MJX-TEX-N-32"></use></g><g data-mml-node="mo" transform="translate(889,0)"><use data-c="29" xlink:href="#MJX-TEX-N-29"></use></g></g></g><g data-mml-node="mo" transform="translate(6774.6,0)"><use data-c="2C" xlink:href="#MJX-TEX-N-2C"></use></g><g data-mml-node="mo" transform="translate(7219.3,0)"><use data-c="2026" xlink:href="#MJX-TEX-N-2026"></use></g><g data-mml-node="mo" transform="translate(8557.9,0)"><use data-c="2C" xlink:href="#MJX-TEX-N-2C"></use></g><g data-mml-node="msup" transform="translate(9002.6,0)"><g data-mml-node="mi"><use data-c="1D45A" xlink:href="#MJX-TEX-I-1D45A"></use></g><g data-mml-node="TeXAtom" transform="translate(911,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><use data-c="28" xlink:href="#MJX-TEX-N-28"></use></g><g data-mml-node="mi" transform="translate(389,0)"><use data-c="1D43F" xlink:href="#MJX-TEX-I-1D43F"></use></g><g data-mml-node="mo" transform="translate(1070,0)"><use data-c="29" xlink:href="#MJX-TEX-N-29"></use></g></g></g><g data-mml-node="mo" transform="translate(10995.3,0)"><use data-c="29" xlink:href="#MJX-TEX-N-29"></use></g></g></g></svg></mjx-container> defines one specific subnetwork (one â€œmemberâ€ of the ensemble).</p>
<div class="expressive-code"><figure class="frame not-content"><figcaption class="header"></figcaption><pre data-language="plaintext" class="wrap" style="--ecMaxLine:265ch"><code><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">1</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">**During training:** Randomly turn off some neurons (like flipping a coin for each one). This forces the network to learn many different "sub-networks" â€” each time you train, a different combination of neurons is active.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">2</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">3</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">**During testing (inference):** Instead of picking one sub-network, we use all neurons, but scale down their strength (usually by half if dropout rate is 50%). This is the "mean network."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">4</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">5</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">&#x3C;span class="def-mono-gold">Why this is like an ensemble:&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">6</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">Imagine you could run the model 1,000 times (or $2^{(N)}$ times for N neurons), each time with a different random set of neurons turned off, and then average all their predictions. **That would be a huge ensemble of sub-networks** â€” very accurate, but way too slow.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">7</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">Dropoutâ€™s trick: Using the scaled "mean network" at test time gives exactly the same prediction as if you had averaged the geometric mean of all those possible sub-networks.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">8</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">9</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">&#x3C;span class="def-mono-blue">Dropout = training lots of sub-networks, inference = using their collective average â€” fast and smart.&#x3C;/span></span></div></div></code></pre></figure></div>
<p>??? question â€œWhat is the curse of dimensionality? How do positional encodings mitigate it in Transformers?â€
<span class="def-mono-blue">Higher dimensions â†’ sparser data â†’ harder to learn meaningful relationships.</span></p>
<div class="expressive-code"><figure class="frame not-content"><figcaption class="header"></figcaption><pre data-language="plaintext" class="wrap" style="--ecMaxLine:156ch"><code><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">1</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">The curse of dimensionality refers to the set of problems that arise when data or model representations exist in high-dimensional spaces.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">2</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">3</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- **Data sparsity:** Points become exponentially sparse â€” distances between points tend to concentrate, making similarity less meaningful.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">4</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- **Combinatorial explosion:** The volume of the space grows exponentially $O(k^{(d)})$, so covering it requires exponentially more data.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">5</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- **Poor generalization:** Models struggle to learn smooth mappings because thereâ€™s too little data to constrain the high-dimensional space.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">6</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">7</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">8</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">**Token in Transformers**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">9</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">Transformers process tokens as vectors in a **high-dimensional** embedding space (e.g., 768 or 4096 dimensions).</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">10</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">However â€” *self-attention* treats each token as a set element rather than a sequence element. The attention mechanism itself has no built-in sense of order.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">11</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">*The model only knows â€œcontent similarity,â€ not which token came first or last.*</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">12</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">13</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">Without order, the model would need to **learn positional relationships implicitly** across high-dimensional embeddings.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">14</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">Thatâ€™s hard â€” and it exacerbates the curse of dimensionality because:</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">15</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:1ch"><div class="gutter"><div class="ln" aria-hidden="true">16</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e"> </span></span><span style="--0:#e1e4e8;--1:#24292e">- Thereâ€™s no geometric bias for position.</span></div></div><div class="ec-line" style="--ecIndent:1ch"><div class="gutter"><div class="ln" aria-hidden="true">17</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e"> </span></span><span style="--0:#e1e4e8;--1:#24292e">- Each token embedding can drift freely in a massive space.</span></div></div><div class="ec-line" style="--ecIndent:1ch"><div class="gutter"><div class="ln" aria-hidden="true">18</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e"> </span></span><span style="--0:#e1e4e8;--1:#24292e">- The model must infer ordering purely from statistical co-occurrence â€” *requiring more data and more parameters.*</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">19</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:1ch"><div class="gutter"><div class="ln" aria-hidden="true">20</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e"> </span></span><span style="--0:#e1e4e8;--1:#24292e">**How Positional Encodings Help**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">21</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:1ch"><div class="gutter"><div class="ln" aria-hidden="true">22</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e"> </span></span><span style="--0:#e1e4e8;--1:#24292e">**Positional encodings (PEs)** inject structured, low-dimensional information about sequence order directly into the embeddings.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">23</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- Adds a geometric bias to embeddings â€” nearby positions have nearby encodings.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">24</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- Reduces the effective search space â€” positions are no longer independent random vectors.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">25</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- Enables extrapolation: the sinusoidal pattern generalizes beyond training positions.</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">26</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- The model can compute relative positions via linear operations (e.g., dot products of PEs reflect distance).</span></div></div></code></pre></figure></div>
<p>??? question â€œExplain maximum likelihood estimation for language modeling.â€
Training a neural LM (like a Transformer) by minimizing the negative log-likelihood (NLL) is the same as maximizing the likelihood:</p>
<div class="expressive-code"><figure class="frame not-content"><figcaption class="header"></figcaption><pre data-language="plaintext" class="wrap" style="--ecMaxLine:133ch"><code><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">1</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">$$\boxed{</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">2</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">\text{Maximizing likelihood}</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">3</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">\;\; \Leftrightarrow \;\;</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">4</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">\text{Maximizing log-likelihood}</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">5</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">\;\; \Leftrightarrow \;\;</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">6</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">\text{Minimizing negative log-likelihood}</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">7</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">}$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">8</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">9</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">**Example**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">10</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> Sentence: "The cat sat on the mat."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">11</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">12</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> The MLE objective trains the model to maximize:</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">13</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> $P(\text{The}) \cdot P(\text{cat}|\text{The}) \cdot P(\text{sat}|\text{The cat}) \cdot P(\text{on}|\text{The cat sat}) \cdot \dots$</span></div></div></code></pre></figure></div>
<p>??? question â€œWhat is negative log-likelihood? Write the per-token loss for GPT.â€</p>
<div class="expressive-code"><figure class="frame not-content"><figcaption class="header"></figcaption><pre data-language="plaintext" class="wrap" style="--ecMaxLine:73ch"><code><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">1</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">$$\boxed{</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">2</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">\ell(\theta) = \sum_{t=1}^T \log P(x_t \mid x_{&#x3C;t}; \theta)</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">3</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">}</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">4</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">5</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">6</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">$$\boxed{</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">7</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">\text{NLL}(\theta) = -\ell(\theta)</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">8</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">}</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">9</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">10</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">11</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">$$\boxed{</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">12</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">\text{NLL}(\theta) = -\sum_{t=1}^T \log P(x_t \mid x_{&#x3C;t}; \theta)</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">13</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">}</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">14</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">15</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">16</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">**where** $x_{&#x3C;t}$ means **All tokens** before $t$: $x_1, \dots, x_{t-1}$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">17</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">&#x3C;!-- $$\boxed{</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">18</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">x_{&#x3C;t} = \text{the past context used to predict } x_t</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">19</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">}$$ --></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">20</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">21</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">This is the heart of autoregressive language modeling â€” like GPT!</span></div></div></code></pre></figure></div>
<p>??? question â€œCompare cross-entropy, perplexity, and BLEU. When is perplexity misleading?â€</p>
<div class="expressive-code"><figure class="frame not-content"><figcaption class="header"></figcaption><pre data-language="plaintext" class="wrap" style="--ecMaxLine:217ch"><code><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">1</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">1. **Cross-Entropy:** Cross-entropy measures how well a probabilistic model predicts a target distribution â€” in LM, how well the model assigns high probability to the correct next tokens.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">2</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">2. **Perplexity:** Perplexity (PPL) is simply the exponentiation of the cross-entropy</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">3</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">3. **BLEU (Bilingual Evaluation Understudy):** BLEU is an n-gram overlap metric for evaluating machine translation or text generation quality against reference texts</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">4</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">5</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">&#x3C;span class="def-mono-blue">Perplexity is rephrasing cross-entropy in a more intuitive, more human-readable.&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">6</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">7</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> **Perplexity = "How predictable is the language?"**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">8</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">9</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> **BLEU = "How much does the output match a reference?"**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">10</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">11</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> Example:</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">12</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">13</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> Reference: "The cat is on the mat."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">14</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">15</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> Model output: "The dog is on the mat."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">16</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">17</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> â†’ Low perplexity (grammatical, fluent)</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">18</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">19</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> â†’ Low BLEU (wrong content)</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">20</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">> **BLEU is non-probabilistic and reference-based â€” unlike cross-entropy and perplexity.**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">21</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">22</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">23</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">âš ï¸ &#x3C;span class="def-mono-red">When Perplexity Is Misleading???&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">24</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">25</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">**Perplexity only measures how well the model predicts tokens probabilistically â€” not how meaningful or correct the generated text is.**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">26</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">27</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- Different tokenizations or vocabularies</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">28</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- A model with smaller tokens or subwords might have lower perplexity just because predictions are more granular, not actually better linguistically.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">29</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- Domain mismatch</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">30</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- A model trained on Wikipedia might have low perplexity on Wikipedia text but produce incoherent answers to questions â€” it knows probabilities, not task structure.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">31</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- Human-aligned vs statistical objectives</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">32</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- A model can assign high likelihood to grammatical but dull continuations (e.g., â€œThe cat sat on the matâ€) while rejecting creative or rare but correct continuations â€” good perplexity, poor real-world usefulness.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">33</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- Non-autoregressive or non-likelihood models</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">34</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- For encoder-decoder or retrieval-augmented systems, perplexity may not correlate with generation quality because these models are not optimized purely for next-token prediction.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">35</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- Overfitting</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">36</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">- A model with very low perplexity on training data may memorize text, but generalize poorly (BLEU or human eval drops).</span></div></div></code></pre></figure></div>
<p>??? question â€œWhy is label smoothing used in LLMs? Derive its modified loss?â€
<strong>Label smoothing is used in LLMs to prevent overconfidence and improve generalization.</strong></p>
<div class="expressive-code"><figure class="frame not-content"><figcaption class="header"></figcaption><pre data-language="plaintext" class="wrap" style="--ecMaxLine:178ch"><code><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">1</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">Instead of training on a **one-hot** target (where the correct token has probability 1 and all others 0), a small portion Îµ of that probability is spread across all other tokens.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">2</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">3</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">So the true token gets (1 âˆ’ Îµ) probability, and the rest share Îµ uniformly.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">4</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">5</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">This changes the loss from the usual â€œâˆ’log p(correct token)â€ to a mix of:</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">6</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:1ch"><div class="gutter"><div class="ln" aria-hidden="true">7</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e"> </span></span><span style="--0:#e1e4e8;--1:#24292e">- `(1 âˆ’ Îµ) Ã— loss` for the correct token, and</span></div></div><div class="ec-line" style="--ecIndent:1ch"><div class="gutter"><div class="ln" aria-hidden="true">8</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e"> </span></span><span style="--0:#e1e4e8;--1:#24292e">- `Îµ Ã— average loss` over all tokens.</span></div></div></code></pre></figure></div>
<p>??? question â€œWhat is the difference between hard and soft attention?â€
- Hard attention â†’ discrete, selective, non-differentiable.
- Soft attention â†’ continuous, weighted, differentiable.</p>
<div class="sl-heading-wrapper level-h2"><h2 id="fundamentals-of-large-language-models-llms">Fundamentals of Large Language Models (LLMs)</h2><a class="sl-anchor-link" href="#fundamentals-of-large-language-models-llms"><span aria-hidden="true" class="sl-anchor-icon"><svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentcolor" d="m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z"></path></svg></span><span class="sr-only" data-pagefind-ignore="">Section titled â€œFundamentals of Large Language Models (LLMs)â€</span></a></div>
<p>!!! Abstract â€œQuestion Bankâ€</p>
<div class="expressive-code"><figure class="frame not-content" style="--lnWidth:3ch"><figcaption class="header"></figcaption><pre data-language="plaintext" class="wrap" style="--ecMaxLine:157ch"><code><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">1</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">Fundamentals of Large Language Models (LLMs)&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">2</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">3</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "LLM Basic"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">4</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">5</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the main open-source LLM families currently available?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">6</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">7</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Llama: Decoder-Only</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">8</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Mistral: Decoder-Only (MoE in Mixtral)</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">9</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Gemma: Decoder-Only</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">10</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Phi: Decoder-Only</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">11</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Qwen: Decoder-Only (dense + MoE)</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">12</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- DeepSeek: Decoder-Only (MoE in V2)</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">13</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Falcon: Decoder-Only</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">14</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- OLMo: Decoder-Only</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">15</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">16</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">17</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the difference between prefix decoder, causal decoder, and encoder-decoder architectures?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">18</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">19</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Causal Decoder (Decoder-Only)**: Autoregressive model that generates text left-to-right, attending only to previous tokens.</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">20</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Prefix Decoder (PrefixLM)**: Causal decoder with a bidirectional prefix (input context) followed by autoregressive generation.</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">21</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- **Encoder-Decoder (Seq2Seq)**: Two separate Transformer stacks(Encoder &#x26; Decoder)</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">22</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">23</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">??? Example "Causal Decoder"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">24</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">25</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Prompt</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">26</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> Translate to French: The cat is on the mat.</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">27</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Generation (autoregressive, causal mask):</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">28</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> Le [only sees "Le"]</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">29</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">30</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> Le chat [sees "Le chat"]</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">31</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">32</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> Le chat est [sees "Le chat est"]</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">33</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">34</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> Le chat est sur [sees up to "sur"]</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">35</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">36</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> Le chat est sur le [sees up to "le"]</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">37</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">38</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> Le chat est sur le tapis. [final]</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">39</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Summary</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">40</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> **Cannot see future tokens**</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">41</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">></span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">42</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> **Cannot see full input bidirectionally â€” but works via prompt engineering**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">43</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">44</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">??? Example "Prefix Decoder"</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">45</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Input Format</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">46</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> [Prefix] The cat is on the mat. [SEP] Translate to French: [Generate] Le chat est sur le tapis.</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">47</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Attention</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">48</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">> **Prefix** (The cat is on the mat. [SEP] Translate to French:) â†’ bidirectional</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">49</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">50</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">??? Example "Encoder-Decoder"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">51</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">52</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">53</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is the training objective of large language models?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">54</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">55</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">LLMs are trained to predict the next token in a sequence.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">56</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">57</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why are most modern LLMs decoder-only architectures?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">58</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">59</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">Most modern LLMs are decoder-only because this architecture is the simplest, fastest, and most flexible for large-scale text generation.</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">60</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">Below is the full reasoning, broken into the fundamental, engineering, and use-case levels.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">61</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:9ch"><div class="gutter"><div class="ln" aria-hidden="true">62</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">         </span></span><span style="--0:#e1e4e8;--1:#24292e">- Decoder-only naturally matches the training objective</span></div></div><div class="ec-line" style="--ecIndent:9ch"><div class="gutter"><div class="ln" aria-hidden="true">63</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">         </span></span><span style="--0:#e1e4e8;--1:#24292e">- Simpler architecture â†’ easier scaling</span></div></div><div class="ec-line" style="--ecIndent:9ch"><div class="gutter"><div class="ln" aria-hidden="true">64</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">         </span></span><span style="--0:#e1e4e8;--1:#24292e">- Better for long-context generation</span></div></div><div class="ec-line" style="--ecIndent:9ch"><div class="gutter"><div class="ln" aria-hidden="true">65</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">         </span></span><span style="--0:#e1e4e8;--1:#24292e">- Fits universal multitask learning with a single text stream</span></div></div><div class="ec-line" style="--ecIndent:9ch"><div class="gutter"><div class="ln" aria-hidden="true">66</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">         </span></span><span style="--0:#e1e4e8;--1:#24292e">- Aligns with inference needs</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">67</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- streaming output</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">68</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- token-by-token generation</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">69</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- low latency</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">70</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- high throughput</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">71</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- continuous prompts</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">72</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">73</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Explain the difference between encoder-only, decoder-only, and encoder-decoder models."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">74</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">75</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-blue">Encoder-only Models (BERT, RoBERTa, DeBERTa, ELECTRA)&#x3C;/span></span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">76</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- classification (sentiment, fraud detection)</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">77</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- named entity recognition</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">78</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- sentence similarity</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">79</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- search / embeddings</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">80</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- anomaly or pattern detection</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">81</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-blue">Decoder-only Models (GPT, Llama, Mixtral, Gemma, Qwen)&#x3C;/span></span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">82</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Text generation</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">83</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Multi-task language modeling</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">84</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Anything that treats tasks as text â†’ text in one stream</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">85</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-blue">Encoderâ€“Decoder (Seq2Seq) Models (T5, FLAN-T5, BART, mT5, early Transformer models)&#x3C;/span></span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">86</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Translation</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">87</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Summarization</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">88</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Text-to-text tasks with clear input â†’ output mapping</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">89</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">90</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the difference between prefix LM and causal LM?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">91</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">92</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">Causal LM&#x3C;/span>: every token can only attend to previous tokens.</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">93</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">Prefix LM&#x3C;/span>: the prefix can be fully bidirectional, while the rest is generated causally.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">94</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">95</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">96</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|Feature|Causal LM|Prefix LM|</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">97</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|---|---|---|</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">98</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|Attention|Strictly left-to-right|Prefix: full; Generation: causal|</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">99</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|Use case|Free-form generation|Conditional generation, prefix tuning|</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">100</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|Examples|GPT, Llama, Mixtral|T5 (prefix mode), UL2, some prompt-tuning models|</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">101</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|Future access?|No|Only inside prefix|</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">102</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|Mask complexity|Simple|Mixed masks|</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">103</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">104</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">105</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Layer Normalization Variants"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">106</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">107</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Comparison of LayerNorm vs BatchNorm vs RMSNorm?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">108</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">109</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|Norm|Formula|Pros|Cons|</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">110</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|---|---|---|---|</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">111</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|BatchNorm|Normalize across batch|Great for CNNs|Bad for variable batch / autoregressive decoding|</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">112</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|LayerNorm|Normalize across hidden dim|Stable for Transformers|Slightly more compute than RMSNorm|</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">113</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">|RMSNorm|Normalize only scale|Faster, more stable in LLMs|No centering â†’ sometimes slightly less expressive|</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">114</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">115</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the core idea of DeepNorm?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">116</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">117</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">**DeepNorm keeps the Transformer stable at extreme depths by scaling the residual connections proportionally to the square root of the model depth.**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">118</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">119</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the advantages of DeepNorm?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">120</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">121</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">**DeepNorm = deep models that actually train and perform well, without tricks.**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">122</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">123</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Enables Extremely Deep Transformers (1,000+ layers)</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">124</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Superior Training Stability</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">125</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Improved Optimization Landscape</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">126</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Better Performance on Downstream Tasks</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">127</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- No Architectural Overhead</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">128</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Robust Across Scales and Tasks</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">129</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">130</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the differences when applying LayerNorm at different positions in LLMs?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">131</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">132</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">~~Pre-NormPost-Norm~~ (Original Transformer, 2017)&#x3C;/span>: Normalizes after adding the residual.</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">133</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Pros:</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">134</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Fairly stable for shallow models (&#x3C;12 layers)</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">135</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Works well in classic NMT models</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">136</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Cons:</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">137</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Fails to train deep models (vanishing/exploding gradients)</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">138</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Poor gradient flow</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">139</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Not used in modern LLMs</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">140</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Pre-Norm (Current Standard in GPT/LLaMA): Normalize before attention or feed-forward</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">141</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Pros:</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">142</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Much more stable for deep Transformers</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">143</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Great training stability up to hundreds of layers</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">144</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Works well with small batch sizes</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">145</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Default in GPT-2/3, LLaMA, Mistral, Gemma, Phi-3, Qwen2</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">146</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Cons:</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">147</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Residual stream grows in magnitude unless controlled (â†’ RMSNorm or DeepNorm often added)</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">148</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Slightly diminished expressive capacity compared to Post-Norm (but negligible in practice)</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">149</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- Sandwich-Norm: LayerNorm applied before AND after sublayers.</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">150</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Pros:</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">151</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Extra stability &#x26; smoothness</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">152</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Improved optimization in some NMT models</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">153</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">154</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">- Cons:</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">155</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Expensive (two norms per sublayer)</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">156</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Rarely used in large decoder-only LLMs</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">157</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">158</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">159</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">160</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">ðŸ§  Why LayerNorm position matters</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">161</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">162</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">1. Training Stability</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">163</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">â€¢  Pre-Norm prevents exploding residuals</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">164</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">â€¢  Post-Norm accumulates errors â†’ unstable for deep models</span></div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">165</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">2. Gradient Flow</span></div></div><div class="ec-line" style="--ecIndent:16ch"><div class="gutter"><div class="ln" aria-hidden="true">166</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">                </span></span><span style="--0:#e1e4e8;--1:#24292e">- Residuals in Pre-Norm allow gradients to bypass the sublayers directly.</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">167</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">168</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">169</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">170</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Which normalization method is used in different LLM architectures?"</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">171</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">**Large decoder-only LLMs almost universally use RMSNorm + Pre-Norm.**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">172</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">173</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Activation Functions in LLMs"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">174</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">175</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the formula for the FFN (Feed-Forward Network) block?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">176</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">177</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">Standard FFN Formula&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">178</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">179</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">$$\text{FFN}(x) = W_2 \, \sigma(W_1 x + b_1) + b_2$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">180</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">181</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">$$W_1 \in \mathbb{R}^{d_{\text{ff}} \times d_{\text{mode$$l}}}$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">182</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">183</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">$$b_1 \in \mathbb{R}^{d_{\text{ff}}}$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">184</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">185</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">$$W_2 \in \mathbb{R}^{d_{\text{model}} \times d_{\text{ff}}}$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">186</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">187</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">$$b_2 \in \mathbb{R}^{d_{\text{model}}}$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">188</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">189</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">$$\sigma = \text{activation} \text{ }  \text{function} \text{(ReLU in original Transformer, GELU in GPT, SwiGLU/GeLU-linear in modern LLMs)}$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">190</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">191</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-blue">Gated FFN in LLMs&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">192</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">193</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">$$\text{FFN}(x) = W_3 \left( \text{Swish}(W_1x) \odot W_2x \right)$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">194</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">195</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">$$\text{Swish}(u) = u \cdot \sigma(u)$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">196</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">197</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">$$W_1, W_2 \in \mathbb{R}^{d_{\text{ff}} \times d_{\text{model}}}$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">198</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:12ch"><div class="gutter"><div class="ln" aria-hidden="true">199</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">            </span></span><span style="--0:#e1e4e8;--1:#24292e">$$W_3 \in \mathbb{R}^{d_{\text{model}} \times d_{\text{ff}}}$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">200</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">201</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">202</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the GeLU formula?"</span></div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">203</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">**Gaussian Error Linear Unit (GeLU)**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">204</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">205</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">$$\text{GeLU}(x) = \frac{x}{2}\left(1 + \operatorname{erf}\left(\frac{x}{\sqrt{2}}\right)\right)$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">206</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">207</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">$$\operatorname{erf}(x) = \frac{2}{\sqrt{\pi}} \int_0^x e^{-t^2} \, dt$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">208</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">209</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the Swish formula?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">210</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">211</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">**Swish is a smooth, non-monotonic activation.**</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">212</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:8ch"><div class="gutter"><div class="ln" aria-hidden="true">213</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">        </span></span><span style="--0:#e1e4e8;--1:#24292e">$$\text{Swish}(x) = \frac{x}{1 + e^{-x}}$$</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">214</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">215</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the formula of an FFN block with GLU (Gated Linear Unit)?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">216</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">217</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the formula of a GLU block using GeLU?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">218</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">219</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the formula of a GLU block using Swish?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">220</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">221</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Which activation functions do popular LLMs use?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">222</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">223</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the differences between Adam and SGD optimizers?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">224</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">225</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">226</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Attention Mechanisms â€” Advanced Topics"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">227</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">228</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the problems with traditional attention?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">229</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">230</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the directions of improvement for attention?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">231</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">232</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the attention variants?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">233</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">234</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What issues exist in multi-head attention?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">235</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">236</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Explain Multi-Query Attention (MQA)."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">237</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">238</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Compare Multi-head, Multi-Query, and Grouped-Query Attention."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">239</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">240</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the benefits of MQA?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">241</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">242</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Which models use MQA or GQA?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">243</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">244</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why was FlashAttention introduced? Briefly explain its core idea."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">245</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">246</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are FlashAttention advantages?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">247</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">248</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Which models implement FlashAttention?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">249</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">250</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is parallel transformer block?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">251</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">252</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the computational complexity of attention and how can it be improved?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">253</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">254</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Compare MHA, GQA, and MQA â€” what are their key differences?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">255</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">256</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">257</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">258</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Cross-Attention"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">259</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">260</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why do we need Cross-Attention?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">261</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">262</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Explain Cross-Attention."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">263</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">264</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Compare Cross-Attention and Self-Attention â€” similarities and differences."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">265</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">266</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Provide a code implementation of Cross-Attention."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">267</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">268</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are its application scenarios?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">269</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">270</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the advantages and challenges of Cross-Attention?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">271</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">272</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">273</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Transformer Operations"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">274</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">275</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to load a BERT model using transformers?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">276</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">277</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to output a specific hidden_state from BERT using transformers?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">278</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">279</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to get the final or intermediate layer vector outputs of BERT?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">280</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">281</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">282</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "LLM Loss Functions"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">283</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">284</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is KL divergence?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">285</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">286</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Write the cross-entropy loss and explain its meaning."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">287</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">288</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the difference between KL divergence and cross-entropy?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">289</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">290</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to handle large loss differences in multi-task learning?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">291</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">292</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why is cross-entropy preferred over MSE for classification tasks?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">293</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">294</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is information gain?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">295</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">296</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to compute softmax and cross-entropy loss (and binary cross-entropy)?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">297</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">298</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What if the exponential term in softmax overflows the float limit?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">299</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">300</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">301</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Similarity &#x26; Contrastive Learning"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">302</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">303</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Besides cosine similarity, what other similarity metrics exist?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">304</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">305</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is contrastive learning?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">306</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">307</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How important are negative samples in contrastive learning, and how to handle costly negative sampling?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">308</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">309</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">310</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">311</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">Advanced Topics in LLMs&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">312</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">313</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Advanced LLM"</span></div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">314</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is a generative large model?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">315</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">316</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How do LLMs make generated text diverse and non-repetitive?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">317</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">318</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is the repetition problem (LLM echo problem)? Why does it happen? How can it be mitigated?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">319</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">320</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Can LLaMA handle infinitely long inputs? Explain why?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">321</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">322</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "When should you use BERT vs. LLaMA / ChatGLM models?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">323</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">324</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Do different domains require their own domain-specific LLMs? Why?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">325</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">326</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to enable an LLM to process longer texts?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">327</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">328</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">329</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">Fine-Tuning Large Models&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">330</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">331</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "General Fine-Tuning"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">332</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">333</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why does the loss drop suddenly in the second epoch during SFT?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">334</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">335</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How much VRAM is needed for full fine-tuning?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">336</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">337</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why do models seem dumber after SFT?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">338</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">339</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to construct instruction fine-tuning datasets?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">340</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">341</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to improve prompt representativeness?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">342</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">343</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to increase prompt data volume?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">344</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">345</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to select domain data for continued pretraining?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">346</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">347</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to prevent forgetting general abilities after domain tuning?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">348</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">349</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to make the model learn more knowledge during pretraining?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">350</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">351</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "When performing SFT, should the base model be Chat or Base?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">352</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">353</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the input/output format for domain fine-tuning?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">354</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">355</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to build a domain evaluation set?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">356</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">357</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Is vocabulary expansion necessary? Why?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">358</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">359</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to train your own LLM?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">360</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">361</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the benefits of instruction fine-tuning?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">362</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">363</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "During which stage â€” pretraining or fine-tuning â€” is knowledge injected?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">364</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">365</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">366</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "SFT Tricks"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">367</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">368</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the typical SFT workflow?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">369</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">370</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are key aspects of training data?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">371</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">372</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to choose between large and small models?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">373</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">374</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to ensure multi-task training balance?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">375</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">376</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Can SFT learn knowledge at all?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">377</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">378</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to select datasets effectively?</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">379</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">380</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Training Experience"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">381</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">382</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to choose a distributed training framework?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">383</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">384</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are key LLM training tips?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">385</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">386</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to choose model size?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">387</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">388</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to select GPU accelerators?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">389</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">390</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">391</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">392</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">LangChain and Agent-Based Systems&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">393</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">394</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">395</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "LangChain Core"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">396</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">397</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is LangChain?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">398</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">399</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are its core concepts?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">400</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">401</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Components and Chains"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">402</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">403</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Prompt Templates and Values"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">404</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">405</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Example Selectors"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">406</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">407</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Output Parsers"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">408</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">409</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Indexes and Retrievers"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">410</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">411</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Chat Message History"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">412</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">413</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Agents and Toolkits"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">414</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">415</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Long-Term Memory in Multi-Turn Conversations"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">416</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">417</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How can Agents access conversation context?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">418</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">419</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Retrieve full history"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">420</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">421</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Use sliding window for recent context"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">422</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">423</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">424</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">425</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Practical RAG Q&#x26;A using LangChain"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">426</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">427</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "(Practical implementation questions about RAG apps in LangChain)"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">428</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">429</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">430</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">Retrieval-Augmented Generation (RAG)&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">431</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">432</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">433</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "RAG Basics"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">434</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">435</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why do LLMs need an external (vector) knowledge base?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">436</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">437</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the overall workflow of LLM+VectorDB document chat?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">438</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">439</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the core technologies?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">440</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">441</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to build an effective prompt template?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">442</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">443</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip " RAG Concepts"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">444</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">445</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the limitations of base LLMs that RAG solves?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">446</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">447</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is RAG?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">448</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">449</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to obtain accurate semantic representations?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">450</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">451</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to align query/document semantic spaces?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">452</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">453</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to match retrieval model output with LLM preferences?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">454</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">455</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to improve results via post-retrieval processing?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">456</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">457</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to optimize generator adaptation to inputs?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">458</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">459</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the benefits of using RAG?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">460</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">461</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "RAG Layout Analysis"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">462</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">463</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why is PDF parsing necessary?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">464</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">465</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are common methods and their differences?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">466</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">467</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What problems exist in PDF parsing?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">468</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">469</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why is table recognition important?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">470</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">471</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the main methods?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">472</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">473</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Traditional methods"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">474</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">475</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "pdfplumber extraction techniques"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">476</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">477</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why do we need text chunking?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">478</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">479</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are common chunking strategies (regex, Spacy, LangChain, etc.)?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">480</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">481</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">482</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">483</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "RAG Retrieval Strategies"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">484</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">485</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why use LLMs to assist recall?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">486</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">487</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "HYDE approach: idea and issues"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">488</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">489</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "FLARE approach: idea and recall strategies"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">490</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">491</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why construct hard negative samples?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">492</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">493</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Random sampling vs. Top-K hard negative sampling"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">494</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">495</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">496</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "RAG Evaluation"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">497</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">498</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why evaluate RAG?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">499</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">500</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the evaluation methods, metrics, and frameworks?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">501</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">502</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">503</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">504</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "RAG Optimization"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">505</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">506</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the optimization strategies for retrieval and generation modules?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">507</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">508</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to enhance context using knowledge graphs (KGs)?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">509</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">510</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the problems with vector-based context augmentation?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">511</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">512</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How can KG-based methods improve it?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">513</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">514</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What are the main pain points in RAG and their solutions?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">515</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">516</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Content missing"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">517</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">518</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Top-ranked docs missed"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">519</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">520</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Context loss"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">521</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">522</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Failure to extract answers"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">523</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">524</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Explain RAG-Fusion. Why itâ€™s needed,Core technologies,Workflow, and Advantages"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">525</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">526</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question ""</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">527</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">528</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">529</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Graph RAG"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">530</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">531</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why do we need Graph RAG?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">532</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">533</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is Graph RAG and how does it work? Show a code example and use case."</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">534</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">535</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How to improve ranking optimization in Graph RAG?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">536</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">537</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">538</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">- &#x3C;span class="def-mono-red">Parameter-Efficient Fine-Tuning (PEFT)&#x3C;/span></span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">539</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">540</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "PEFT Fundamentals"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">541</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">542</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is fine-tuning, and how is it performed?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">543</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">544</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why do we need PEFT?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">545</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">546</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "What is PEFT and its advantages?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">547</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">548</div></div><div class="code">
</div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">549</div></div><div class="code"><span style="--0:#e1e4e8;--1:#24292e">??? tip "Adapter Tuning"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">550</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">551</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Why use adapter-tuning?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">552</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">553</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "Whatâ€™s the core idea behind adapter-tuning?"</span></div></div><div class="ec-line"><div class="gutter"><div class="ln" aria-hidden="true">554</div></div><div class="code">
</div></div><div class="ec-line" style="--ecIndent:4ch"><div class="gutter"><div class="ln" aria-hidden="true">555</div></div><div class="code"><span class="indent"><span style="--0:#e1e4e8;--1:#24292e">    </span></span><span style="--0:#e1e4e8;--1:#24292e">??? question "How does it differ from full fine-tuning?"</span></div></div></code></pre></figure></div><style>
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}
</style> </div> <footer class="sl-flex astro-sz7xmlte"> <div class="meta sl-flex astro-sz7xmlte"> <p class="copyright astro-sz7xmlte">
&copy; 2026 Bin Zhang. All rights reserved.
</p> </div> <div class="socials sl-flex astro-sz7xmlte"> <a href="https://github.com/binzhango" rel="me" class="astro-sz7xmlte"> <svg aria-hidden="true" class="astro-sz7xmlte astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M12 .3a12 12 0 0 0-3.8 23.38c.6.12.83-.26.83-.57L9 21.07c-3.34.72-4.04-1.61-4.04-1.61-.55-1.39-1.34-1.76-1.34-1.76-1.08-.74.09-.73.09-.73 1.2.09 1.83 1.24 1.83 1.24 1.08 1.83 2.81 1.3 3.5 1 .1-.78.42-1.31.76-1.61-2.67-.3-5.47-1.33-5.47-5.93 0-1.31.47-2.38 1.24-3.22-.14-.3-.54-1.52.1-3.18 0 0 1-.32 3.3 1.23a11.5 11.5 0 0 1 6 0c2.28-1.55 3.29-1.23 3.29-1.23.64 1.66.24 2.88.12 3.18a4.65 4.65 0 0 1 1.23 3.22c0 4.61-2.8 5.63-5.48 5.92.42.36.81 1.1.81 2.22l-.01 3.29c0 .31.2.69.82.57A12 12 0 0 0 12 .3Z"/></svg> </a> <a href="https://discord.com/invite/binzhango" rel="me" class="astro-sz7xmlte"> <svg aria-hidden="true" class="astro-sz7xmlte astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="M20.32 4.37a19.8 19.8 0 0 0-4.93-1.51 13.78 13.78 0 0 0-.64 1.28 18.27 18.27 0 0 0-5.5 0 12.64 12.64 0 0 0-.64-1.28h-.05A19.74 19.74 0 0 0 3.64 4.4 20.26 20.26 0 0 0 .11 18.09l.02.02a19.9 19.9 0 0 0 6.04 3.03l.04-.02a14.24 14.24 0 0 0 1.23-2.03.08.08 0 0 0-.05-.07 13.1 13.1 0 0 1-1.9-.92.08.08 0 0 1 .02-.1 10.2 10.2 0 0 0 .41-.31h.04a14.2 14.2 0 0 0 12.1 0l.04.01a9.63 9.63 0 0 0 .4.32.08.08 0 0 1-.03.1 12.29 12.29 0 0 1-1.9.91.08.08 0 0 0-.02.1 15.97 15.97 0 0 0 1.27 2.01h.04a19.84 19.84 0 0 0 6.03-3.05v-.03a20.12 20.12 0 0 0-3.57-13.69ZM8.02 15.33c-1.18 0-2.16-1.08-2.16-2.42 0-1.33.96-2.42 2.16-2.42 1.21 0 2.18 1.1 2.16 2.42 0 1.34-.96 2.42-2.16 2.42Zm7.97 0c-1.18 0-2.15-1.08-2.15-2.42 0-1.33.95-2.42 2.15-2.42 1.22 0 2.18 1.1 2.16 2.42 0 1.34-.94 2.42-2.16 2.42Z"/></svg> </a> <a href="https://www.threads.net/@binzhango" rel="me" class="astro-sz7xmlte"> <svg aria-hidden="true" class="astro-sz7xmlte astro-c6vsoqas" width="16" height="16" viewBox="0 0 24 24" fill="currentColor" style="--sl-icon-size: 1em;"><path d="m17.73 11.2-.29-.13c-.17-3.13-1.88-4.92-4.75-4.94h-.04c-1.72 0-3.14.73-4.02 2.06l1.58 1.09a2.8 2.8 0 0 1 2.47-1.21c.94 0 1.66.28 2.12.81.33.4.56.93.67 1.61-.84-.14-1.74-.18-2.71-.13-2.73.16-4.49 1.75-4.37 3.97a3.41 3.41 0 0 0 1.57 2.71c.81.54 1.85.8 2.93.74a4.32 4.32 0 0 0 3.33-1.62 6 6 0 0 0 1.14-2.97 3.5 3.5 0 0 1 1.46 1.6 4 4 0 0 1-.98 4.4c-1.3 1.3-2.86 1.85-5.21 1.87-2.62-.02-4.6-.86-5.88-2.5-1.2-1.52-1.82-3.73-1.85-6.56.03-2.83.65-5.04 1.85-6.57 1.29-1.63 3.26-2.47 5.88-2.49 2.63.02 4.64.86 5.97 2.5.66.8 1.15 1.82 1.48 3l1.85-.5c-.4-1.44-1.02-2.7-1.86-3.73-1.71-2.1-4.21-3.19-7.44-3.21h-.01c-3.22.02-5.7 1.1-7.35 3.22C3.79 6.1 3.03 8.72 3 11.99V12c.03 3.29.79 5.9 2.27 7.78 1.66 2.12 4.13 3.2 7.35 3.22h.01c2.86-.02 4.88-.77 6.54-2.43a5.95 5.95 0 0 0 1.4-6.56 5.62 5.62 0 0 0-2.84-2.81Zm-4.94 4.64c-1.2.07-2.44-.47-2.5-1.62-.05-.85.6-1.8 2.57-1.92l.67-.02c.71 0 1.38.07 1.99.2-.23 2.84-1.56 3.3-2.73 3.36Z"/></svg> </a> </div> </footer>  </div><button class="back-to-top" aria-label="Back to top" title="Back to top"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor"> <path d="M12 4l-8 8h5v8h6v-8h5z"></path> </svg> </button> </div>  </main> </div> </div>  </div> </div>  </body></html>