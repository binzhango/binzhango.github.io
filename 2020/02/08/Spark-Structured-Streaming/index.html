<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Spark Structured Streaming · Bin's Blog</title><meta name="description" content="Spark Structured Streaming - Bin Zhang"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/prontera.css"><link rel="search" type="application/opensearchdescription+xml" href="https://github.com/binzhango/binzhango.github.io/atom.xml" title="Bin's Blog"><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Bin's Blog" type="application/atom+xml">
<!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><header class="feature-header"><nav class="component-nav"><ul><div class="logo-container"><a href="/"><h2 class="title">Bin's Blog</h2></a></div><a href="/" target="_self" class="li component-nav-item"><p>INDEX</p></a><a href="/archives" target="_self" class="li component-nav-item"><p>ARCHIVES</p></a><ul class="shortcut-icons"><a href="https://github.com/AngryPowman" target="_blank"><img src="/images/github.svg" class="icon"></a><a href="/atom.xml" target="_blank"><img src="/images/rss.svg" class="icon"></a></ul></ul></nav></header><main class="container"><div id="post-container"><div class="post"><article class="post-block"><h1 class="post-title">Spark Structured Streaming</h1><div class="post-info">Feb 8, 2020</div><div class="post-content"><h2 id="spark-structured-streaming"><a class="markdownIt-Anchor" href="#spark-structured-streaming"></a> Spark Structured Streaming</h2>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>Recently reading a blog <a href="https://hackersandslackers.com/structured-streaming-in-pyspark/" target="_blank" rel="noopener">Structured Streaming in PySpark</a><br />
It’s implemented in Databricks platform. Then I try to reimplement in my local Spark.<br />
Some tricky issue happend during my work.</p>
<h2 id="reading-data"><a class="markdownIt-Anchor" href="#reading-data"></a> Reading Data</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> TimestampType, StringType, StructType, StructField</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"Test Streaming"</span>).enableHiveSupport().getOrCreate()</span><br><span class="line"></span><br><span class="line">json_schema = StructType([</span><br><span class="line">    StructField(<span class="string">"time"</span>, TimestampType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">"customer"</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">"action"</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">"device"</span>, StringType(), <span class="literal">True</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">file_path = <span class="string">"local_file_path&lt;file:///..."</span></span><br></pre></td></tr></table></figure>
<h4 id="read-json-as-same-as-method-in-the-blog"><a class="markdownIt-Anchor" href="#read-json-as-same-as-method-in-the-blog"></a> read json as same as method in the blog</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">input = spark.read.schema(json_schema).json(file_path)</span><br><span class="line"></span><br><span class="line">input.show()</span><br><span class="line"><span class="comment"># +----+--------+------+------+</span></span><br><span class="line"><span class="comment"># |time|customer|action|device|</span></span><br><span class="line"><span class="comment"># +----+--------+------+------+</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># +----+--------+------+------+</span></span><br><span class="line">input.count()</span><br><span class="line"><span class="comment"># 20000</span></span><br></pre></td></tr></table></figure>
<p>All values are null, however, the count is right. It means spark has already read all data but the schema is not correctly mapped.</p>
<h4 id="read-a-single-json-file-to-check-schema"><a class="markdownIt-Anchor" href="#read-a-single-json-file-to-check-schema"></a> read a single json file to check schema</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">input = spark.read.schema(json_schema).json(file_path+<span class="string">'/1.json'</span>)</span><br><span class="line"></span><br><span class="line">input.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># +----+--------+------+------+</span></span><br><span class="line"><span class="comment"># |time|customer|action|device|</span></span><br><span class="line"><span class="comment"># +----+--------+------+------+</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># |null|    null|  null|  null|</span></span><br><span class="line"><span class="comment"># +----+--------+------+------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># same error</span></span><br><span class="line"><span class="comment"># Then I drop schema option and use inferSchema</span></span><br><span class="line">input = spark.read.json(file_path+<span class="string">'/1.json'</span>)</span><br><span class="line"></span><br><span class="line">input.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># +--------------------+-----------+-----------------+--------------------+---------------+</span></span><br><span class="line"><span class="comment"># |     _corrupt_record|     action|         customer|              device|           time|</span></span><br><span class="line"><span class="comment"># +--------------------+-----------+-----------------+--------------------+---------------+</span></span><br><span class="line"><span class="comment"># |[&#123;"time":"3:57:09...|       null|             null|                null|           null|</span></span><br><span class="line"><span class="comment"># |                null|  power off|Nicolle Pargetter| August Doorbell Cam| 1:29:05.000 AM|</span></span><br><span class="line"><span class="comment"># |                null|   power on|   Concordia Muck|Footbot Air Quali...| 6:02:06.000 AM|</span></span><br><span class="line"><span class="comment"># |                null|  power off| Kippar McCaughen|             ecobee4| 5:40:19.000 PM|</span></span><br><span class="line"><span class="comment"># |                null|  power off|    Sidney Jotham|  GreenIQ Controller| 4:54:28.000 PM|</span></span><br><span class="line"><span class="comment"># |                null|  power off|    Fanya Menzies|             ecobee4| 3:12:48.000 PM|</span></span><br><span class="line"><span class="comment"># |                null|low battery|    Jeanne Gresch|             ecobee4| 5:39:47.000 PM|</span></span><br><span class="line"><span class="comment"># |                null|   power on|    Chen Cuttelar| August Doorbell Cam| 2:45:44.000 PM|</span></span><br><span class="line"><span class="comment"># |                null|  power off|       Merwyn Mix|         Amazon Echo| 9:23:41.000 PM|</span></span><br><span class="line"><span class="comment"># |                null|  power off| Angelico Conrath|         Amazon Echo| 4:53:13.000 AM|</span></span><br><span class="line"><span class="comment"># |                null|   power on|     Gilda Emmett| August Doorbell Cam|12:32:29.000 AM|</span></span><br><span class="line"><span class="comment"># |                null|low battery|  Austine Davsley|             ecobee4| 3:35:12.000 AM|</span></span><br><span class="line"><span class="comment"># |                null|low battery| Zackariah Thoday|         Amazon Echo| 1:26:13.000 PM|</span></span><br><span class="line"><span class="comment"># |                null|  power off|     Ewen Gillson|         Amazon Echo| 7:47:20.000 AM|</span></span><br><span class="line"><span class="comment"># |                null|   power on|     Itch Durnill|             ecobee4| 4:45:55.000 AM|</span></span><br><span class="line"><span class="comment"># |                null|  power off|        Winni Dow|  GreenIQ Controller| 4:12:54.000 AM|</span></span><br><span class="line"><span class="comment"># |                null|   power on|Talbot Valentelli| August Doorbell Cam| 7:35:23.000 PM|</span></span><br><span class="line"><span class="comment"># |                null|low battery|    Vikki Muckeen| August Doorbell Cam| 1:17:30.000 PM|</span></span><br><span class="line"><span class="comment"># |                null|  power off|  Christie Karran|Footbot Air Quali...| 9:38:13.000 PM|</span></span><br><span class="line"><span class="comment"># |                null|low battery|     Evonne Guest|         Amazon Echo| 8:02:21.000 AM|</span></span><br><span class="line"><span class="comment"># +--------------------+-----------+-----------------+--------------------+---------------+</span></span><br></pre></td></tr></table></figure>
<p>A weird column is <em>_corrupt_record</em> and first value is <strong>[{“time”:&quot;3:57:09…</strong> in this column.<br />
Go back to check source file and notice that it’s a list of object in json file.</p>
<h6 id="remove-span-stylecolorred-span-and-span-stylecolorred-span-in-source-file"><a class="markdownIt-Anchor" href="#remove-span-stylecolorred-span-and-span-stylecolorred-span-in-source-file"></a> Remove  <span style='color:red'> <em>[</em> </span> and <span style='color:red'><em>]</em> </span> in source file</h6>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">input = spark.read.json(file_path+<span class="string">'/1.json'</span>)</span><br><span class="line"></span><br><span class="line">input.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># +-----------+-----------------+--------------------+---------------+</span></span><br><span class="line"><span class="comment"># |     action|         customer|              device|           time|</span></span><br><span class="line"><span class="comment"># +-----------+-----------------+--------------------+---------------+</span></span><br><span class="line"><span class="comment"># |  power off|      Alexi Barts|  GreenIQ Controller| 3:57:09.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off|Nicolle Pargetter| August Doorbell Cam| 1:29:05.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|   Concordia Muck|Footbot Air Quali...| 6:02:06.000 AM|</span></span><br><span class="line"><span class="comment"># |  power off| Kippar McCaughen|             ecobee4| 5:40:19.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off|    Sidney Jotham|  GreenIQ Controller| 4:54:28.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off|    Fanya Menzies|             ecobee4| 3:12:48.000 PM|</span></span><br><span class="line"><span class="comment"># |low battery|    Jeanne Gresch|             ecobee4| 5:39:47.000 PM|</span></span><br><span class="line"><span class="comment"># |   power on|    Chen Cuttelar| August Doorbell Cam| 2:45:44.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off|       Merwyn Mix|         Amazon Echo| 9:23:41.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off| Angelico Conrath|         Amazon Echo| 4:53:13.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|     Gilda Emmett| August Doorbell Cam|12:32:29.000 AM|</span></span><br><span class="line"><span class="comment"># |low battery|  Austine Davsley|             ecobee4| 3:35:12.000 AM|</span></span><br><span class="line"><span class="comment"># |low battery| Zackariah Thoday|         Amazon Echo| 1:26:13.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off|     Ewen Gillson|         Amazon Echo| 7:47:20.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|     Itch Durnill|             ecobee4| 4:45:55.000 AM|</span></span><br><span class="line"><span class="comment"># |  power off|        Winni Dow|  GreenIQ Controller| 4:12:54.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|Talbot Valentelli| August Doorbell Cam| 7:35:23.000 PM|</span></span><br><span class="line"><span class="comment"># |low battery|    Vikki Muckeen| August Doorbell Cam| 1:17:30.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off|  Christie Karran|Footbot Air Quali...| 9:38:13.000 PM|</span></span><br><span class="line"><span class="comment"># |low battery|     Evonne Guest|         Amazon Echo| 8:02:21.000 AM|</span></span><br><span class="line"><span class="comment"># +-----------+-----------------+--------------------+---------------+</span></span><br></pre></td></tr></table></figure>
<p>Woo, the dataframe is correct. Let’s check schema</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">input.printSchema()</span><br><span class="line"><span class="comment"># root</span></span><br><span class="line"><span class="comment">#  |-- action: string (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- customer: string (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- device: string (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- time: string (nullable = true)</span></span><br></pre></td></tr></table></figure>
<p>So far I manually modify source file and drop external schema to obtain a corret dataframe. Is there anyway to<br />
read these files without these steps.</p>
<h6 id="add-one-feature-span-stylecolorbluemultilinespan"><a class="markdownIt-Anchor" href="#add-one-feature-span-stylecolorbluemultilinespan"></a> add one feature <span style='color:blue'>multiLine</span></h6>
<p>Read the file without schema but add one feature <strong>multiLine</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">input = spark.read.json(<span class="string">"file:///path/pyspark_test_data"</span>, multiLine=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># OR input = spark.read.option('multiLine', True).json("file:///path/pyspark_test_data")</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># +-----------+--------------------+--------------------+---------------+</span></span><br><span class="line"><span class="comment"># |     action|            customer|              device|           time|</span></span><br><span class="line"><span class="comment"># +-----------+--------------------+--------------------+---------------+</span></span><br><span class="line"><span class="comment"># |   power on|     Raynor Blaskett|Nest T3021US Ther...| 3:35:09.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|Stafford Blakebrough|  GreenIQ Controller|10:59:46.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|      Alex Woolcocks|Nest T3021US Ther...| 6:26:36.000 PM|</span></span><br><span class="line"><span class="comment"># |   power on|      Clarice Nayshe|Footbot Air Quali...| 4:46:28.000 AM|</span></span><br><span class="line"><span class="comment"># |  power off|      Killie Pirozzi|Footbot Air Quali...| 8:58:43.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|    Lynne Dymidowicz|Footbot Air Quali...| 4:20:49.000 PM|</span></span><br><span class="line"><span class="comment"># |   power on|       Shaina Dowyer|             ecobee4| 3:41:33.000 AM|</span></span><br><span class="line"><span class="comment"># |low battery|       Barbee Melato| August Doorbell Cam|10:40:24.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off|        Clem Westcot|Nest T3021US Ther...|11:13:38.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off|       Kerri Galfour|         Amazon Echo|10:12:15.000 PM|</span></span><br><span class="line"><span class="comment"># |low battery|        Trev Ashmore|  GreenIQ Controller|11:04:41.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|      Coral Jahnisch| August Doorbell Cam| 3:06:31.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|      Feliza Cowdrey|Nest T3021US Ther...| 2:49:02.000 AM|</span></span><br><span class="line"><span class="comment"># |  power off|   Amabelle De Haven|Footbot Air Quali...|12:11:59.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off|     Benton Redbourn|Nest T3021US Ther...| 3:57:39.000 AM|</span></span><br><span class="line"><span class="comment"># |low battery|        Asher Potten| August Doorbell Cam| 1:34:44.000 AM|</span></span><br><span class="line"><span class="comment"># |low battery|    Lorianne Hullyer| August Doorbell Cam| 7:26:42.000 PM|</span></span><br><span class="line"><span class="comment"># |  power off|     Ruperto Aldcorn|Footbot Air Quali...| 3:54:49.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|   Agatha Di Giacomo|Footbot Air Quali...| 7:15:20.000 AM|</span></span><br><span class="line"><span class="comment"># |   power on|    Eunice Penwright|             ecobee4|11:14:14.000 PM|</span></span><br><span class="line"><span class="comment"># +-----------+--------------------+--------------------+---------------+</span></span><br><span class="line"></span><br><span class="line">input.printSchema()</span><br><span class="line"></span><br><span class="line"><span class="comment"># root</span></span><br><span class="line"><span class="comment">#  |-- action: string (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- customer: string (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- device: string (nullable = true)</span></span><br><span class="line"><span class="comment">#  |-- time: string (nullable = true)</span></span><br></pre></td></tr></table></figure>
<h4 id="change-the-schema"><a class="markdownIt-Anchor" href="#change-the-schema"></a> change the schema</h4>
<p>Set time as <em>StringType</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">json_schema = StructType([</span><br><span class="line">    StructField(<span class="string">"time"</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">"customer"</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">"action"</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">"device"</span>, StringType(), <span class="literal">True</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input = spark.read.schema(json_schema).json(<span class="string">"file:///path/pyspark_test_data"</span>, multiLine=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">input.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># +---------------+--------------------+-----------+--------------------+</span></span><br><span class="line"><span class="comment"># |           time|            customer|     action|              device|</span></span><br><span class="line"><span class="comment"># +---------------+--------------------+-----------+--------------------+</span></span><br><span class="line"><span class="comment"># | 3:35:09.000 AM|     Raynor Blaskett|   power on|Nest T3021US Ther...|</span></span><br><span class="line"><span class="comment"># |10:59:46.000 AM|Stafford Blakebrough|   power on|  GreenIQ Controller|</span></span><br><span class="line"><span class="comment"># | 6:26:36.000 PM|      Alex Woolcocks|   power on|Nest T3021US Ther...|</span></span><br><span class="line"><span class="comment"># | 4:46:28.000 AM|      Clarice Nayshe|   power on|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># | 8:58:43.000 AM|      Killie Pirozzi|  power off|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># | 4:20:49.000 PM|    Lynne Dymidowicz|   power on|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># | 3:41:33.000 AM|       Shaina Dowyer|   power on|             ecobee4|</span></span><br><span class="line"><span class="comment"># |10:40:24.000 PM|       Barbee Melato|low battery| August Doorbell Cam|</span></span><br><span class="line"><span class="comment"># |11:13:38.000 PM|        Clem Westcot|  power off|Nest T3021US Ther...|</span></span><br><span class="line"><span class="comment"># |10:12:15.000 PM|       Kerri Galfour|  power off|         Amazon Echo|</span></span><br><span class="line"><span class="comment"># |11:04:41.000 AM|        Trev Ashmore|low battery|  GreenIQ Controller|</span></span><br><span class="line"><span class="comment"># | 3:06:31.000 AM|      Coral Jahnisch|   power on| August Doorbell Cam|</span></span><br><span class="line"><span class="comment"># | 2:49:02.000 AM|      Feliza Cowdrey|   power on|Nest T3021US Ther...|</span></span><br><span class="line"><span class="comment"># |12:11:59.000 PM|   Amabelle De Haven|  power off|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># | 3:57:39.000 AM|     Benton Redbourn|  power off|Nest T3021US Ther...|</span></span><br><span class="line"><span class="comment"># | 1:34:44.000 AM|        Asher Potten|low battery| August Doorbell Cam|</span></span><br><span class="line"><span class="comment"># | 7:26:42.000 PM|    Lorianne Hullyer|low battery| August Doorbell Cam|</span></span><br><span class="line"><span class="comment"># | 3:54:49.000 AM|     Ruperto Aldcorn|  power off|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># | 7:15:20.000 AM|   Agatha Di Giacomo|   power on|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># |11:14:14.000 PM|    Eunice Penwright|   power on|             ecobee4|</span></span><br><span class="line"><span class="comment"># +---------------+--------------------+-----------+--------------------+</span></span><br></pre></td></tr></table></figure>
<p>Pyspark can load json files successfully without TimestampType. However, how to handle timestamp issue in this job?</p>
<h4 id="timestamptype"><a class="markdownIt-Anchor" href="#timestamptype"></a> TimestampType</h4>
<p>In offical document, the class <em>pyspark.sql.DataFrameReader</em> has one parameter</p>
<ul>
<li>timestampFormat</li>
</ul>
<blockquote>
<p>sets the string that indicates a timestamp format.</p>
<p>Custom date formats follow the formats at java.text.SimpleDateFormat.</p>
<p>This applies to timestamp type. If None is set, it uses the default value, yyyy-MM-dd’T’HH:mm:ss.SSSXXX.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">input = spark.read.schema(schema).option(<span class="string">"multiLine"</span>, <span class="literal">True</span>).json(<span class="string">"file:///path/pyspark_test_data"</span>, timestampFormat=<span class="string">"h:mm:ss.SSS aa"</span>)</span><br><span class="line"></span><br><span class="line">input.show()</span><br><span class="line"><span class="comment"># +-------------------+--------------------+-----------+--------------------+</span></span><br><span class="line"><span class="comment"># |               time|            customer|     action|              device|</span></span><br><span class="line"><span class="comment"># +-------------------+--------------------+-----------+--------------------+</span></span><br><span class="line"><span class="comment"># |1970-01-01 03:35:09|     Raynor Blaskett|   power on|Nest T3021US Ther...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 10:59:46|Stafford Blakebrough|   power on|  GreenIQ Controller|</span></span><br><span class="line"><span class="comment"># |1970-01-01 18:26:36|      Alex Woolcocks|   power on|Nest T3021US Ther...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 04:46:28|      Clarice Nayshe|   power on|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 08:58:43|      Killie Pirozzi|  power off|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 16:20:49|    Lynne Dymidowicz|   power on|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 03:41:33|       Shaina Dowyer|   power on|             ecobee4|</span></span><br><span class="line"><span class="comment"># |1970-01-01 22:40:24|       Barbee Melato|low battery| August Doorbell Cam|</span></span><br><span class="line"><span class="comment"># |1970-01-01 23:13:38|        Clem Westcot|  power off|Nest T3021US Ther...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 22:12:15|       Kerri Galfour|  power off|         Amazon Echo|</span></span><br><span class="line"><span class="comment"># |1970-01-01 11:04:41|        Trev Ashmore|low battery|  GreenIQ Controller|</span></span><br><span class="line"><span class="comment"># |1970-01-01 03:06:31|      Coral Jahnisch|   power on| August Doorbell Cam|</span></span><br><span class="line"><span class="comment"># |1970-01-01 02:49:02|      Feliza Cowdrey|   power on|Nest T3021US Ther...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 12:11:59|   Amabelle De Haven|  power off|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 03:57:39|     Benton Redbourn|  power off|Nest T3021US Ther...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 01:34:44|        Asher Potten|low battery| August Doorbell Cam|</span></span><br><span class="line"><span class="comment"># |1970-01-01 19:26:42|    Lorianne Hullyer|low battery| August Doorbell Cam|</span></span><br><span class="line"><span class="comment"># |1970-01-01 03:54:49|     Ruperto Aldcorn|  power off|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 07:15:20|   Agatha Di Giacomo|   power on|Footbot Air Quali...|</span></span><br><span class="line"><span class="comment"># |1970-01-01 23:14:14|    Eunice Penwright|   power on|             ecobee4|</span></span><br><span class="line"><span class="comment"># +-------------------+--------------------+-----------+--------------------+</span></span><br></pre></td></tr></table></figure>
<p>All yyyy-MM-dd are 1970-01-01 because source file only hh-mm-ss.<br />
These source files are in wrong format in Windows.</p>
<h2 id="streaming-our-data"><a class="markdownIt-Anchor" href="#streaming-our-data"></a> Streaming Our Data</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> TimestampType, StringType, StructType, StructField</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"Test Streaming"</span>).enableHiveSupport().getOrCreate()</span><br><span class="line"></span><br><span class="line">json_schema = StructType([</span><br><span class="line">    StructField(<span class="string">"time"</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">"customer"</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">"action"</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">"device"</span>, StringType(), <span class="literal">True</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">streamingDF = spark.readStream.schema(json_schema) \</span><br><span class="line">              .option(<span class="string">"maxFilesPerTrigger"</span>, <span class="number">1</span>) \</span><br><span class="line">              .option(<span class="string">"multiLine"</span>, <span class="literal">True</span>) \</span><br><span class="line">              .json(<span class="string">"file:///path/pyspark_test_data"</span>)</span><br><span class="line"></span><br><span class="line">streamingActionCountsDF = streamingDF.groupBy(<span class="string">'action'</span>).count()</span><br><span class="line"><span class="comment"># streamingActionCountsDF.isStreaming</span></span><br><span class="line">spark.conf.set(<span class="string">"spark.sql.shuffle.partitions"</span>, <span class="string">"2"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># View stream in real-time</span></span><br><span class="line"><span class="comment"># query = streamingActionCountsDF.writeStream \</span></span><br><span class="line"><span class="comment">#         .format("memory").queryName("counts").outputMode("complete").start()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># format choice:</span></span><br><span class="line"><span class="comment"># parquet</span></span><br><span class="line"><span class="comment"># kafka</span></span><br><span class="line"><span class="comment"># console</span></span><br><span class="line"><span class="comment"># memory</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># query = streamingActionCountsDF.writeStream \</span></span><br><span class="line"><span class="comment">#         .format("console").queryName("counts").outputMode("complete").start()</span></span><br><span class="line"></span><br><span class="line">query = streamingActionCountsDF.writeStream.format(<span class="string">"console"</span>) \</span><br><span class="line">        .queryName(<span class="string">"counts"</span>).outputMode(<span class="string">"complete"</span>).start().awaitTermination(timeout=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># Output Mode choice:</span></span><br><span class="line"><span class="comment"># append</span></span><br><span class="line"><span class="comment"># complete</span></span><br><span class="line"><span class="comment"># update</span></span><br></pre></td></tr></table></figure>
</div></article></div><div id="disqus_thread"></div></div><script>var disqus_shortname = 'angrypowman';
var disqus_identifier = '2020/02/08/Spark-Structured-Streaming/';
var disqus_title = 'Spark Structured Streaming';
var disqus_url = 'https://github.com/binzhango/binzhango.github.io/2020/02/08/Spark-Structured-Streaming/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//angrypowman.disqus.com/count.js" async></script></main><footer class="footer-container"><div class="paginator"><a href="/2020/02/11/Whitening-transformation/" class="prev">PREV</a><a href="/2020/02/04/Batch-Normalization/" class="next">NEXT</a></div><div class="copyright"><p>© 2017 - 2020 <a href="https://github.com/binzhango/binzhango.github.io">Bin Zhang</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/AngryPowman/hexo-theme-prontera" target="_blank">hexo-theme-prontera</a>.</p></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"angrypowman",'auto');ga('send','pageview');</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>