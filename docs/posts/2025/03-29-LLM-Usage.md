---
title: GenAI Projects
authors:
  - BZ
date: 2025-03-29
pin: true
categories: 
  - LLM
---

<!-- more -->

>
> Learning never exhausts the mind <br>
>  &nbsp; &nbsp; &nbsp; &nbsp; â€• Leonardo da Vinci

## Collections

#### Blogs
|**Name**|**URL**|
|---|---|
|LLM terminology|[Link](https://promptmetheus.com/resources/llm-knowledge-base)|
|A Critical Look at MCP|[Link](https://raz.sh/blog/2025-05-02_a_critical_look_at_mcp)|
|Ilya Rice: How I Won the Enterprise RAG Challenge|[Link](https://abdullin.com/ilya/how-to-build-best-rag/)|


#### Papers
| **Paper** | **Link** | **Preview** |
| --- | --- | --- |
| A Comprehensive Overview of Large Language Models |[Click](https://arxiv.org/abs/2307.06435) | [ref](../../assets/pdfs/2307.06435v10.pdf) |
| KBLaM: Knowledge Base augmented Language Model | [Click](https://arxiv.org/abs/2410.10450)| |
| Retrieval-Augmented Generation for Large Language Models: A Survey | [Click](https://arxiv.org/abs/2312.10997) | [ref](../../assets/pdfs/2312.10997v5.pdf) |
| Revolutionizing Retrieval-Augmented Generation with Enhanced PDF Structure Recognition| [Click](https://arxiv.org/abs/2401.12599)||
| Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models | [Click](https://arxiv.org/abs/2408.05933)||
|<span style="color: red; font-weight:bold;">Google Prompt Engineering whitepaper</span>||[ref](../../assets/pdfs/Google_Engineering_2025.pdf)|
|Speculative Thinking: Enhancing Small-Model Reasoning with Large Model Guidance at Inference Time|[Click](https://arxiv.org/html/2504.12329v1)||
|LLM Post-Training: A Deep Dive into Reasoning Large Language Models||[ref](../../assets/pdfs/2502.21321v2.pdf)|
|Decoder-Only or Encoder-Decoder? Interpreting Language Model as a Regularized Encoder-Decoder|[Click](https://arxiv.org/pdf/2304.04052)||
|What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?|[Click](https://arxiv.org/pdf/2204.05832)||

#### Model/Repository
|**Model/Repository** | **Link**|
|--- | --- |
| ds4sd/SmolDocling-256M-preview | [Hugging Face](https://huggingface.co/ds4sd/SmolDocling-256M-preview)|
| qlib| [GitHub](https://github.com/microsoft/qlib)|
|ByteDance/Dolphin|[Hugging Face](https://huggingface.co/ByteDance/Dolphin)|


## Agent Frameworks

|**Agentic Framework Name**| **Github Link**|
|:---:|:---:|
| LangChain | [GitHub](https://github.com/langchain-ai/langchain)|
| llama_index | [GitHub](https://github.com/run-llama/llama_index)|
| Autogen | [GitHub](https://github.com/microsoft/autogen)|
| Haystack| [GitHub](https://github.com/deepset-ai/haystack) |
| CrewAI (flow) | [GitHub](https://github.com/crewAIInc/crewAI) |
| langflow | [GitHub](https://github.com/langflow-ai/langflow)
| smolagents | [GitHub](https://github.com/huggingface/smolagents) |
| Pydantic AI | [GitHub](https://github.com/pydantic/pydantic-ai) |
| pyspur | [GitHub](https://github.com/PySpur-Dev/pyspur) |
| agno (phiData) | [Github](https://github.com/agno-agi/agno)|
| instructor | [Github](https://github.com/instructor-ai/instructor)|
| **DSpy**| [Github](https://github.com/stanfordnlp/dspy)|
| **JS Only**|---|
| n8n | [GitHub](https://github.com/n8n-io/n8n)|


## **My LLM Working Projects**

### Schema Mapping (Completed)
> LLM can be used to map schema from one format to another. This is useful for data migration and integration.

| Resources | Link|
|---|---|
| blog (inspired by this blog)  | [Blog](https://medium.com/@hamzaahmad6292/llm-based-schema-mapping-for-automated-crm-integration-c4837d1b1ed5) |
| paper (research paper on schema mapping) | [ref](../../assets/pdfs/2407.11852v1.pdf)|

### Feature Engineering (Ongoing)
> LLM can be used to generate features for machine learning models. This can save time and effort in the feature engineering process.

| Resources | Link|
|---|---|
| paper (research paper on schema mapping) | [ref](../../assets/pdfs/2503.14434v2.pdf)|
| paper (research paper on schema mapping) | [ref](../../assets/pdfs/2503.23371v1.pdf)|

### RAG: PDF Converting (Completed)
> LLM can be used to convert PDFs into structured data. This is useful for extracting information from unstructured documents.

### LLM: Fine-Tuning (Ongoing)
> 
